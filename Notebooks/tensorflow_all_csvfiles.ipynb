{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training a neural network on Spectrum Protect data using TensorFlow \n",
      "Loading the Spectrum Protect data to memory...\n",
      "          POOLID    SIZE     OFFSET  LENGTH\n",
      "0             27  481580   83025920   27701\n",
      "1             27  481686   83054592   27517\n",
      "2             27  481686   83083264   20937\n",
      "3             27  125893   48144384   33383\n",
      "4             27  481686   83107840   21768\n",
      "5             27  481686   83132416   27737\n",
      "6             27  481686   83161088   22400\n",
      "7             27  481686   83185664   21981\n",
      "8             27  327415   90664960   21884\n",
      "9             27  327415   90800128   22323\n",
      "10            27  327337   90824704   17923\n",
      "11            27  481580   83210240   22329\n",
      "12            27  481686   83234816   25152\n",
      "13            27  481686   83263488   19543\n",
      "14            27  756310   82366464   19493\n",
      "15            27   25820   82386944     240\n",
      "16            27   50002   82391040    3943\n",
      "17            27  160010   82395136   13375\n",
      "18            27  327415   90845184   26477\n",
      "19            27  327415   90873856   18717\n",
      "20            27  327415   90894336   20415\n",
      "21            27    2048  102379520     990\n",
      "22            27   50002   12673024   26485\n",
      "23            27    9888   42999808     177\n",
      "24            27  210169  102408192  104482\n",
      "25            27   45052   12066816   20821\n",
      "26            27  327415   91095040   20109\n",
      "27            27  160010   82411520   11781\n",
      "28            27  160010   82423808   10026\n",
      "29            27  160010   82436096   12176\n",
      "...          ...     ...        ...     ...\n",
      "14379134      71   50002   14954496    2193\n",
      "14379135      71   50062   14958592    2228\n",
      "14379136      71   50002   14962688    2167\n",
      "14379137      71   32622   14966784    1399\n",
      "14379138      71  305519   14970880   54963\n",
      "14379139      71   50002   15028224    1558\n",
      "14379140      71   50002   15032320    1588\n",
      "14379141      71   50002   15036416    1570\n",
      "14379142      71   50002   15040512    1563\n",
      "14379143      71   50083   15044608    1611\n",
      "14379144      71   50012   15048704    1567\n",
      "14379145      71   50002   15052800    1603\n",
      "14379146      71   50058   15056896    1544\n",
      "14379147      71   50002   15060992    1572\n",
      "14379148      71   50002   15065088    1573\n",
      "14379149      71   50020   15069184    1548\n",
      "14379150      71   50002   15073280    1558\n",
      "14379151      71   50011   15077376    1586\n",
      "14379152      71   50002   15081472    1624\n",
      "14379153      71   50002   15085568    1576\n",
      "14379154      71   50028   15089664    1593\n",
      "14379155      71   50002   15093760    1555\n",
      "14379156      71   50002   15097856    1600\n",
      "14379157      71   50011   15101952    1577\n",
      "14379158      71   50002   15106048    1577\n",
      "14379159      71   50002   15110144    1612\n",
      "14379160      71   32662   15114240     987\n",
      "14379161      71  305519   15118336   50107\n",
      "14379162      71   50002   15171584    1569\n",
      "14379163      71   50002   15175680    1511\n",
      "\n",
      "[14379164 rows x 4 columns]\n",
      "Finish loading\n"
     ]
    }
   ],
   "source": [
    "path = 'Data/merge_data/4_features'                     \n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_dataset   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "print(\"\\nTraining a neural network on Spectrum Protect data using TensorFlow \")\n",
    "print(\"Loading the Spectrum Protect data to memory...\")\n",
    "# Loading the dataset\n",
    "# dataset = pd.read_csv('ourdata.csv')\n",
    "print(concatenated_dataset)\n",
    "print(\"Finish loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            SIZE     OFFSET  LENGTH  POOLID_24  POOLID_27  POOLID_37  \\\n",
      "0         481580   83025920   27701          0          1          0   \n",
      "1         481686   83054592   27517          0          1          0   \n",
      "2         481686   83083264   20937          0          1          0   \n",
      "3         125893   48144384   33383          0          1          0   \n",
      "4         481686   83107840   21768          0          1          0   \n",
      "5         481686   83132416   27737          0          1          0   \n",
      "6         481686   83161088   22400          0          1          0   \n",
      "7         481686   83185664   21981          0          1          0   \n",
      "8         327415   90664960   21884          0          1          0   \n",
      "9         327415   90800128   22323          0          1          0   \n",
      "10        327337   90824704   17923          0          1          0   \n",
      "11        481580   83210240   22329          0          1          0   \n",
      "12        481686   83234816   25152          0          1          0   \n",
      "13        481686   83263488   19543          0          1          0   \n",
      "14        756310   82366464   19493          0          1          0   \n",
      "15         25820   82386944     240          0          1          0   \n",
      "16         50002   82391040    3943          0          1          0   \n",
      "17        160010   82395136   13375          0          1          0   \n",
      "18        327415   90845184   26477          0          1          0   \n",
      "19        327415   90873856   18717          0          1          0   \n",
      "20        327415   90894336   20415          0          1          0   \n",
      "21          2048  102379520     990          0          1          0   \n",
      "22         50002   12673024   26485          0          1          0   \n",
      "23          9888   42999808     177          0          1          0   \n",
      "24        210169  102408192  104482          0          1          0   \n",
      "25         45052   12066816   20821          0          1          0   \n",
      "26        327415   91095040   20109          0          1          0   \n",
      "27        160010   82411520   11781          0          1          0   \n",
      "28        160010   82423808   10026          0          1          0   \n",
      "29        160010   82436096   12176          0          1          0   \n",
      "...          ...        ...     ...        ...        ...        ...   \n",
      "14379134   50002   14954496    2193          0          0          0   \n",
      "14379135   50062   14958592    2228          0          0          0   \n",
      "14379136   50002   14962688    2167          0          0          0   \n",
      "14379137   32622   14966784    1399          0          0          0   \n",
      "14379138  305519   14970880   54963          0          0          0   \n",
      "14379139   50002   15028224    1558          0          0          0   \n",
      "14379140   50002   15032320    1588          0          0          0   \n",
      "14379141   50002   15036416    1570          0          0          0   \n",
      "14379142   50002   15040512    1563          0          0          0   \n",
      "14379143   50083   15044608    1611          0          0          0   \n",
      "14379144   50012   15048704    1567          0          0          0   \n",
      "14379145   50002   15052800    1603          0          0          0   \n",
      "14379146   50058   15056896    1544          0          0          0   \n",
      "14379147   50002   15060992    1572          0          0          0   \n",
      "14379148   50002   15065088    1573          0          0          0   \n",
      "14379149   50020   15069184    1548          0          0          0   \n",
      "14379150   50002   15073280    1558          0          0          0   \n",
      "14379151   50011   15077376    1586          0          0          0   \n",
      "14379152   50002   15081472    1624          0          0          0   \n",
      "14379153   50002   15085568    1576          0          0          0   \n",
      "14379154   50028   15089664    1593          0          0          0   \n",
      "14379155   50002   15093760    1555          0          0          0   \n",
      "14379156   50002   15097856    1600          0          0          0   \n",
      "14379157   50011   15101952    1577          0          0          0   \n",
      "14379158   50002   15106048    1577          0          0          0   \n",
      "14379159   50002   15110144    1612          0          0          0   \n",
      "14379160   32662   15114240     987          0          0          0   \n",
      "14379161  305519   15118336   50107          0          0          0   \n",
      "14379162   50002   15171584    1569          0          0          0   \n",
      "14379163   50002   15175680    1511          0          0          0   \n",
      "\n",
      "          POOLID_38  POOLID_60  POOLID_71  POOLID_83  POOLID_95  POOLID_112  \\\n",
      "0                 0          0          0          0          0           0   \n",
      "1                 0          0          0          0          0           0   \n",
      "2                 0          0          0          0          0           0   \n",
      "3                 0          0          0          0          0           0   \n",
      "4                 0          0          0          0          0           0   \n",
      "5                 0          0          0          0          0           0   \n",
      "6                 0          0          0          0          0           0   \n",
      "7                 0          0          0          0          0           0   \n",
      "8                 0          0          0          0          0           0   \n",
      "9                 0          0          0          0          0           0   \n",
      "10                0          0          0          0          0           0   \n",
      "11                0          0          0          0          0           0   \n",
      "12                0          0          0          0          0           0   \n",
      "13                0          0          0          0          0           0   \n",
      "14                0          0          0          0          0           0   \n",
      "15                0          0          0          0          0           0   \n",
      "16                0          0          0          0          0           0   \n",
      "17                0          0          0          0          0           0   \n",
      "18                0          0          0          0          0           0   \n",
      "19                0          0          0          0          0           0   \n",
      "20                0          0          0          0          0           0   \n",
      "21                0          0          0          0          0           0   \n",
      "22                0          0          0          0          0           0   \n",
      "23                0          0          0          0          0           0   \n",
      "24                0          0          0          0          0           0   \n",
      "25                0          0          0          0          0           0   \n",
      "26                0          0          0          0          0           0   \n",
      "27                0          0          0          0          0           0   \n",
      "28                0          0          0          0          0           0   \n",
      "29                0          0          0          0          0           0   \n",
      "...             ...        ...        ...        ...        ...         ...   \n",
      "14379134          0          0          1          0          0           0   \n",
      "14379135          0          0          1          0          0           0   \n",
      "14379136          0          0          1          0          0           0   \n",
      "14379137          0          0          1          0          0           0   \n",
      "14379138          0          0          1          0          0           0   \n",
      "14379139          0          0          1          0          0           0   \n",
      "14379140          0          0          1          0          0           0   \n",
      "14379141          0          0          1          0          0           0   \n",
      "14379142          0          0          1          0          0           0   \n",
      "14379143          0          0          1          0          0           0   \n",
      "14379144          0          0          1          0          0           0   \n",
      "14379145          0          0          1          0          0           0   \n",
      "14379146          0          0          1          0          0           0   \n",
      "14379147          0          0          1          0          0           0   \n",
      "14379148          0          0          1          0          0           0   \n",
      "14379149          0          0          1          0          0           0   \n",
      "14379150          0          0          1          0          0           0   \n",
      "14379151          0          0          1          0          0           0   \n",
      "14379152          0          0          1          0          0           0   \n",
      "14379153          0          0          1          0          0           0   \n",
      "14379154          0          0          1          0          0           0   \n",
      "14379155          0          0          1          0          0           0   \n",
      "14379156          0          0          1          0          0           0   \n",
      "14379157          0          0          1          0          0           0   \n",
      "14379158          0          0          1          0          0           0   \n",
      "14379159          0          0          1          0          0           0   \n",
      "14379160          0          0          1          0          0           0   \n",
      "14379161          0          0          1          0          0           0   \n",
      "14379162          0          0          1          0          0           0   \n",
      "14379163          0          0          1          0          0           0   \n",
      "\n",
      "          POOLID_114  POOLID_138  \n",
      "0                  0           0  \n",
      "1                  0           0  \n",
      "2                  0           0  \n",
      "3                  0           0  \n",
      "4                  0           0  \n",
      "5                  0           0  \n",
      "6                  0           0  \n",
      "7                  0           0  \n",
      "8                  0           0  \n",
      "9                  0           0  \n",
      "10                 0           0  \n",
      "11                 0           0  \n",
      "12                 0           0  \n",
      "13                 0           0  \n",
      "14                 0           0  \n",
      "15                 0           0  \n",
      "16                 0           0  \n",
      "17                 0           0  \n",
      "18                 0           0  \n",
      "19                 0           0  \n",
      "20                 0           0  \n",
      "21                 0           0  \n",
      "22                 0           0  \n",
      "23                 0           0  \n",
      "24                 0           0  \n",
      "25                 0           0  \n",
      "26                 0           0  \n",
      "27                 0           0  \n",
      "28                 0           0  \n",
      "29                 0           0  \n",
      "...              ...         ...  \n",
      "14379134           0           0  \n",
      "14379135           0           0  \n",
      "14379136           0           0  \n",
      "14379137           0           0  \n",
      "14379138           0           0  \n",
      "14379139           0           0  \n",
      "14379140           0           0  \n",
      "14379141           0           0  \n",
      "14379142           0           0  \n",
      "14379143           0           0  \n",
      "14379144           0           0  \n",
      "14379145           0           0  \n",
      "14379146           0           0  \n",
      "14379147           0           0  \n",
      "14379148           0           0  \n",
      "14379149           0           0  \n",
      "14379150           0           0  \n",
      "14379151           0           0  \n",
      "14379152           0           0  \n",
      "14379153           0           0  \n",
      "14379154           0           0  \n",
      "14379155           0           0  \n",
      "14379156           0           0  \n",
      "14379157           0           0  \n",
      "14379158           0           0  \n",
      "14379159           0           0  \n",
      "14379160           0           0  \n",
      "14379161           0           0  \n",
      "14379162           0           0  \n",
      "14379163           0           0  \n",
      "\n",
      "[14379164 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for the categories\n",
    "concatenated_dataset = pd.get_dummies(concatenated_dataset, columns=['POOLID']) \n",
    "values = list(concatenated_dataset.columns.values)\n",
    "print(concatenated_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              SIZE    OFFSET    LENGTH  POOLID_24\n",
      "0         0.117573  0.791813  0.006731        0.0\n",
      "1         0.117599  0.792087  0.006687        0.0\n",
      "2         0.117599  0.792360  0.005080        0.0\n",
      "3         0.030735  0.459150  0.008119        0.0\n",
      "4         0.117599  0.792595  0.005283        0.0\n",
      "5         0.117599  0.792829  0.006740        0.0\n",
      "6         0.117599  0.793102  0.005437        0.0\n",
      "7         0.117599  0.793337  0.005335        0.0\n",
      "8         0.079935  0.864666  0.005311        0.0\n",
      "9         0.079935  0.865955  0.005418        0.0\n",
      "10        0.079916  0.866190  0.004344        0.0\n",
      "11        0.117573  0.793571  0.005420        0.0\n",
      "12        0.117599  0.793806  0.006109        0.0\n",
      "13        0.117599  0.794079  0.004740        0.0\n",
      "14        0.184646  0.785524  0.004728        0.0\n",
      "15        0.006303  0.785719  0.000027        0.0\n",
      "16        0.012207  0.785759  0.000931        0.0\n",
      "17        0.039065  0.785798  0.003234        0.0\n",
      "18        0.079935  0.866385  0.006433        0.0\n",
      "19        0.079935  0.866659  0.004538        0.0\n",
      "20        0.079935  0.866854  0.004953        0.0\n",
      "21        0.000500  0.976387  0.000210        0.0\n",
      "22        0.012207  0.120862  0.006435        0.0\n",
      "23        0.002414  0.410087  0.000012        0.0\n",
      "24        0.051311  0.976661  0.025477        0.0\n",
      "25        0.010999  0.115081  0.005052        0.0\n",
      "26        0.079935  0.868768  0.004878        0.0\n",
      "27        0.039065  0.785954  0.002845        0.0\n",
      "28        0.039065  0.786071  0.002416        0.0\n",
      "29        0.039065  0.786188  0.002941        0.0\n",
      "...            ...       ...       ...        ...\n",
      "14379134  0.012207  0.142620  0.000504        0.0\n",
      "14379135  0.012222  0.142659  0.000512        0.0\n",
      "14379136  0.012207  0.142698  0.000498        0.0\n",
      "14379137  0.007964  0.142737  0.000310        0.0\n",
      "14379138  0.074589  0.142776  0.013387        0.0\n",
      "14379139  0.012207  0.143323  0.000349        0.0\n",
      "14379140  0.012207  0.143362  0.000356        0.0\n",
      "14379141  0.012207  0.143401  0.000352        0.0\n",
      "14379142  0.012207  0.143440  0.000350        0.0\n",
      "14379143  0.012227  0.143480  0.000362        0.0\n",
      "14379144  0.012210  0.143519  0.000351        0.0\n",
      "14379145  0.012207  0.143558  0.000360        0.0\n",
      "14379146  0.012221  0.143597  0.000345        0.0\n",
      "14379147  0.012207  0.143636  0.000352        0.0\n",
      "14379148  0.012207  0.143675  0.000353        0.0\n",
      "14379149  0.012212  0.143714  0.000346        0.0\n",
      "14379150  0.012207  0.143753  0.000349        0.0\n",
      "14379151  0.012209  0.143792  0.000356        0.0\n",
      "14379152  0.012207  0.143831  0.000365        0.0\n",
      "14379153  0.012207  0.143870  0.000353        0.0\n",
      "14379154  0.012214  0.143909  0.000357        0.0\n",
      "14379155  0.012207  0.143948  0.000348        0.0\n",
      "14379156  0.012207  0.143987  0.000359        0.0\n",
      "14379157  0.012209  0.144026  0.000354        0.0\n",
      "14379158  0.012207  0.144065  0.000354        0.0\n",
      "14379159  0.012207  0.144105  0.000362        0.0\n",
      "14379160  0.007974  0.144144  0.000209        0.0\n",
      "14379161  0.074589  0.144183  0.012202        0.0\n",
      "14379162  0.012207  0.144691  0.000352        0.0\n",
      "14379163  0.012207  0.144730  0.000337        0.0\n",
      "\n",
      "[14379164 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Normalization\n",
    "X_train = concatenated_dataset[values[:4]]\n",
    "X_train = ((X_train - X_train.min()) / (X_train.max() - X_train.min())).fillna(0)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2207278e-02 3.3426476e-01 7.4023457e-04 0.0000000e+00]\n",
      " [1.0112308e-03 0.0000000e+00 9.3554711e-04 0.0000000e+00]\n",
      " [5.3747571e-03 4.1321170e-01 3.4760751e-03 0.0000000e+00]\n",
      " ...\n",
      " [1.2212161e-02 6.5852928e-01 4.7143566e-04 0.0000000e+00]\n",
      " [5.2067883e-02 7.4185133e-01 5.2067883e-02 0.0000000e+00]\n",
      " [2.3341388e-01 1.5031563e-01 8.4682390e-02 0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data \n",
    "features = np.array(X_train, dtype='float32')\n",
    "target = np.array(concatenated_dataset[values[4:]], dtype='float32')\n",
    "\n",
    "# Shuffle Data\n",
    "indices = np.random.choice(len(features), len(features), replace=False)\n",
    "X_values = features[indices]\n",
    "y_values = target[indices]\n",
    "\n",
    "# Creating a Train and a Test Dataset\n",
    "test_size = 1000\n",
    "X_test = X_values[-test_size:]\n",
    "X_train = X_values[:-test_size]\n",
    "y_test = y_values[-test_size:]\n",
    "y_train = y_values[:-test_size]\n",
    "\n",
    "# print(X_train)\n",
    "print(X_test)\n",
    "# print(y_test)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/austin/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/austin/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "A neural Network which contains 3 layers with 4, 10, 8 nodes repectively was created!\n"
     ]
    }
   ],
   "source": [
    "# define a neural network\n",
    "\n",
    "# Initialize placeholders\n",
    "X_data = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 10], dtype=tf.float32)\n",
    "\n",
    "#create seed for random_normal()\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "output_nodes = 10\n",
    "hidden_layer_nodes = 10\n",
    "# We create a neural Network which contains 3 layers with 4, 8, 3 nodes repectively\n",
    "w1 = tf.Variable(tf.random_normal(shape=[4,hidden_layer_nodes])) # Weight of the input layer\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))   # Bias of the input layer\n",
    "w2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,output_nodes])) # Weight of the hidden layer\n",
    "b2 = tf.Variable(tf.random_normal(shape=[output_nodes]))                    # Bias of the hidden layer\n",
    "\n",
    "# tf.summary.histogram(\"weights\", w1)\n",
    "# tf.summary.histogram(\"biases\", b1)\n",
    "\n",
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(X_data, w1), b1))\n",
    "final_output = tf.nn.softmax(tf.add(tf.matmul(hidden_output, w2), b2))\n",
    "\n",
    "# Loss Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_target * tf.log(final_output), axis=0))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "print(\"A neural Network which contains 3 layers with 4, 10, 8 nodes repectively was created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-65159db05e34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36madd_summary\u001b[0;34m(self, summary, global_step)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# to save space - we just store the metadata on the first value with a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# specific tag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "print('Training the model...')\n",
    "\n",
    "# Interval / Epochs\n",
    "interval = 100\n",
    "epoch = 1000\n",
    "\n",
    "# Initialize variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "#Logging for Tensorboard\n",
    "merged_summary = tf.summary.merge_all()\n",
    "loss_graph = tf.summary.scalar('loss', loss)\n",
    "writer = tf.summary.FileWriter('graphs', sess.graph)\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "# Training the model...\n",
    "for i in range(1, (epoch + 1)):\n",
    "    s = sess.run(optimizer, feed_dict={X_data: X_train, y_target: y_train})\n",
    "    if i % interval == 0:\n",
    "        #Austin Code that doesnt work\n",
    "        writer.add_summary(s, i)\n",
    "        #######\n",
    "        print('Epoch', i, '|', 'Loss:', sess.run(loss, feed_dict={X_data: X_train, y_target: y_train}))\n",
    "\n",
    "print(\"Training finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is: 0.343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(final_output, 1), tf.argmax(y_target,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"The accuracy of the model is:\", sess.run(accuracy, feed_dict={X_data: X_test, y_target: y_test}))\n",
    "\n",
    "# tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model to predict pool id for features:  [[0.6934 0.     0.0029 0.1481]]\n",
      "\n",
      "Predicted softmax vector is:  [[1.9665e-01 3.4181e-02 1.7584e-04 7.3081e-02 1.2066e-02 6.8273e-01\n",
      "  2.8249e-04 8.4213e-04]]\n",
      "\n",
      "Predicted pool id is:  POOLID_6\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "np.set_printoptions(precision=4)\n",
    "unknown = np.array([[0.693363, 0.0, 0.002894, 0.148097]], dtype=np.float32)\n",
    "predicted = sess.run(final_output, feed_dict={X_data: unknown})\n",
    "# model.predict(unknown)\n",
    "print(\"Using model to predict pool id for features: \", unknown)\n",
    "print(\"\\nPredicted softmax vector is: \",predicted)\n",
    "Class_dict={'POOLID_-1000000': 0, 'POOLID_-9': 1, 'POOLID_-1': 2, 'POOLID_4': 3, 'POOLID_-1': 4, 'POOLID_6': 5, 'POOLID_42': 6, 'POOLID_72': 7, 'POOLID_82': 8 }\n",
    "pool_dict = {v:k for k,v in Class_dict.items()}\n",
    "print(\"\\nPredicted pool id is: \", pool_dict[np.argmax(predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
