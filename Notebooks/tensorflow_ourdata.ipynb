{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training a neural network on Iris dataset using TensorFlow \n",
      "Loading the Iris data to memory...\n",
      "Finish loading\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining a neural network on Iris dataset using TensorFlow \")\n",
    "print(\"Loading the Iris data to memory...\")\n",
    "# Loading the dataset\n",
    "dataset = pd.read_csv('ourdata.csv')\n",
    "print(\"Finish loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          SIZE    OFFSET    LENGTH  POOLID_24  POOLID_27  POOLID_60\n",
      "0     0.000748  0.000000  0.027412          0          0          1\n",
      "1     0.011206  0.000000  0.035966          0          0          1\n",
      "2     0.013513  0.000000  0.036041          0          0          1\n",
      "3     0.013576  0.000000  0.036050          0          0          1\n",
      "4     0.022461  0.000000  0.026706          0          0          1\n",
      "5     0.022461  0.000000  0.026737          0          0          1\n",
      "6     0.022461  0.000000  0.026790          0          0          1\n",
      "7     0.022461  0.000000  0.026811          0          0          1\n",
      "8     0.022461  0.000000  0.026903          0          0          1\n",
      "9     0.022461  0.000000  0.026939          0          0          1\n",
      "10    0.022461  0.000000  0.026974          0          0          1\n",
      "11    0.022461  0.000000  0.026978          0          0          1\n",
      "12    0.022461  0.000000  0.027026          0          0          1\n",
      "13    0.029738  0.750903  0.004619          0          1          0\n",
      "14    0.065620  0.000000  0.076617          0          0          1\n",
      "15    0.065620  0.000000  0.076635          0          0          1\n",
      "16    0.065620  0.000000  0.076701          0          0          1\n",
      "17    0.065620  0.000000  0.076714          0          0          1\n",
      "18    0.065620  0.000000  0.076714          0          0          1\n",
      "19    0.065620  0.000000  0.076722          0          0          1\n",
      "20    0.065620  0.000000  0.076727          0          0          1\n",
      "21    0.065620  0.000000  0.076762          0          0          1\n",
      "22    0.065620  0.000000  0.076779          0          0          1\n",
      "23    0.065620  0.000000  0.076784          0          0          1\n",
      "24    0.065620  0.000000  0.076797          0          0          1\n",
      "25    0.065620  0.000000  0.076815          0          0          1\n",
      "26    0.065620  0.000000  0.076819          0          0          1\n",
      "27    0.065620  0.000000  0.076836          0          0          1\n",
      "28    0.065620  0.000000  0.076841          0          0          1\n",
      "29    0.065620  0.000000  0.076893          0          0          1\n",
      "...        ...       ...       ...        ...        ...        ...\n",
      "1955  0.414804  0.000000  0.999781          1          0          0\n",
      "1956  0.414804  0.000000  0.999781          1          0          0\n",
      "1957  0.414804  0.000000  0.999781          1          0          0\n",
      "1958  0.414804  0.000000  0.999781          1          0          0\n",
      "1959  0.414804  0.000000  0.999781          1          0          0\n",
      "1960  0.414804  0.000000  0.999781          1          0          0\n",
      "1961  0.414804  0.000000  0.999781          1          0          0\n",
      "1962  0.414804  0.000000  0.999781          1          0          0\n",
      "1963  0.414804  0.000000  0.999781          1          0          0\n",
      "1964  0.414804  0.000000  0.999781          1          0          0\n",
      "1965  0.414804  0.000000  0.999781          1          0          0\n",
      "1966  0.414804  0.000000  0.999781          1          0          0\n",
      "1967  0.414804  0.000000  0.999781          1          0          0\n",
      "1968  0.414804  0.000000  0.999781          1          0          0\n",
      "1969  0.414813  0.000000  0.999803          1          0          0\n",
      "1970  0.414817  0.000000  0.999812          1          0          0\n",
      "1971  0.414854  0.000000  0.999899          1          0          0\n",
      "1972  0.414889  0.000000  0.999982          1          0          0\n",
      "1973  0.414897  0.000000  1.000000          1          0          0\n",
      "1974  0.420340  0.720097  0.469525          0          1          0\n",
      "1975  0.422720  0.743312  0.502310          0          1          0\n",
      "1976  0.461510  0.798732  0.078348          0          1          0\n",
      "1977  0.557619  0.996610  0.239121          0          1          0\n",
      "1978  0.577566  0.734173  0.630078          0          1          0\n",
      "1979  0.598571  0.746628  0.623518          0          1          0\n",
      "1980  0.662776  0.509765  0.186002          0          1          0\n",
      "1981  0.694795  0.806839  0.108797          0          1          0\n",
      "1982  0.786313  0.803818  0.353221          0          1          0\n",
      "1983  0.951944  0.807355  0.448367          0          1          0\n",
      "1984  1.000000  0.806250  0.142235          0          1          0\n",
      "\n",
      "[1985 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for the categories\n",
    "dataset = pd.get_dummies(dataset, columns=['POOLID']) \n",
    "values = list(dataset.columns.values)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data \n",
    "target = np.array(dataset[values[-3:]], dtype='float32')\n",
    "features = np.array(dataset[values[0:-3]], dtype='float32')\n",
    "\n",
    "# Shuffle Data\n",
    "indices = np.random.choice(len(features), len(features), replace=False)\n",
    "X_values = features[indices]\n",
    "y_values = target[indices]\n",
    "\n",
    "# Creating a Train and a Test Dataset\n",
    "test_size = 600\n",
    "X_test = X_values[-test_size:]\n",
    "X_train = X_values[:-test_size]\n",
    "y_test = y_values[-test_size:]\n",
    "y_train = y_values[:-test_size]\n",
    "\n",
    "# print(X_train)\n",
    "# print(X_test)\n",
    "print(y_test)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A neural Network which contains 3 layers with 4, 8, 3 nodes repectively was created!\n"
     ]
    }
   ],
   "source": [
    "# define a neural network\n",
    "\n",
    "# Initialize placeholders\n",
    "X_data = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "\n",
    "#create seed for random_normal()\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "hidden_layer_nodes = 8\n",
    "# We create a neural Network which contains 3 layers with 4, 8, 3 nodes repectively\n",
    "w1 = tf.Variable(tf.random_normal(shape=[3,hidden_layer_nodes])) # Weight of the input layer\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))   # Bias of the input layer\n",
    "w2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,3])) # Weight of the hidden layer\n",
    "b2 = tf.Variable(tf.random_normal(shape=[3]))                    # Bias of the hidden layer\n",
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(X_data, w1), b1))\n",
    "final_output = tf.nn.softmax(tf.add(tf.matmul(hidden_output, w2), b2))\n",
    "\n",
    "# Loss Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_target * tf.log(final_output), axis=0))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "print(\"A neural Network which contains 3 layers with 4, 8, 3 nodes repectively was created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 100 | Loss: 160.39238\n",
      "Epoch 200 | Loss: 59.792347\n",
      "Epoch 300 | Loss: 44.70972\n",
      "Epoch 400 | Loss: 31.573957\n",
      "Epoch 500 | Loss: 25.416616\n",
      "Epoch 600 | Loss: 21.959908\n",
      "Epoch 700 | Loss: 19.503973\n",
      "Epoch 800 | Loss: 17.493502\n",
      "Epoch 900 | Loss: 15.923043\n",
      "Epoch 1000 | Loss: 14.898193\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training the model...')\n",
    "\n",
    "# Interval / Epochs\n",
    "interval = 100\n",
    "epoch = 1000\n",
    "\n",
    "# Initialize variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training the model...\n",
    "for i in range(1, (epoch + 1)):\n",
    "    sess.run(optimizer, feed_dict={X_data: X_train, y_target: y_train})\n",
    "    if i % interval == 0:\n",
    "        print('Epoch', i, '|', 'Loss:', sess.run(loss, feed_dict={X_data: X_train, y_target: y_train}))\n",
    "\n",
    "print(\"Training finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is: 0.99666667\n"
     ]
    }
   ],
   "source": [
    "# get the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(final_output, 1), tf.argmax(y_target,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"The accuracy of the model is:\", sess.run(accuracy, feed_dict={X_data: X_test, y_target: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model to predict species for features:  [[0.0823 0.     0.0152]]\n",
      "\n",
      "Predicted softmax vector is:  [[6.2273e-07 3.7796e-06 1.0000e+00]]\n",
      "\n",
      "Predicted species is:  POOLID_60\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "np.set_printoptions(precision=4)\n",
    "unknown = np.array([[0.082286288, 0, 0.015198128]], dtype=np.float32)\n",
    "predicted = sess.run(final_output, feed_dict={X_data: unknown})\n",
    "# model.predict(unknown)\n",
    "print(\"Using model to predict species for features: \", unknown)\n",
    "print(\"\\nPredicted softmax vector is: \",predicted)\n",
    "Class_dict={'POOLID_24': 0, 'POOLID_27': 1, 'POOLID_60': 2}\n",
    "species_dict = {v:k for k,v in Class_dict.items()}\n",
    "print(\"\\nPredicted species is: \", species_dict[np.argmax(predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
