{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to be reflective of your environment\n",
    "data_dir = '/Users/zhaoluyang/Downloads/Senior-Capstone-2018-2019-master/Notebooks/TestData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "size = os.path.getsize(data_dir+\"/BACKUP_OBJECTS.csv\")\n",
    "end = 50 # how many gigs to scale backup objects\n",
    "upscale = int((end * 1073741824) / size)\n",
    "upscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiates a SparkContext which is necessary for accessing data in Spark\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "# change to match your environment\n",
    "output_dir = data_dir + \"/merge_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDRO = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load([data_dir + '/SD_RECON_ORDER.csv'])\n",
    "SS_POOLS = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load([data_dir + '/SS_POOLS.csv'])\n",
    "AFBF = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load([data_dir+\"/AF_BITFILES.csv\"])\n",
    "BACKUP_OBJECTS = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load([data_dir+\"/BACKUP_OBJECTS.csv\"])\n",
    "ls = [SDRO, SS_POOLS, AFBF, BACKUP_OBJECTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53161928\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9adf71eb73a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m         \"\"\"\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# upscale step\n",
    "for i in range(len(ls)):\n",
    "    csv = ls[i]\n",
    "    concat = csv\n",
    "    print(concat.count())\n",
    "    for j in range(upscale):\n",
    "        concat = concat.union(csv)\n",
    "    ls[i] = concat\n",
    "    print(concat.count())\n",
    "    \n",
    "    \n",
    "SDRO = ls[0]\n",
    "SS_POOLS = ls[1]\n",
    "AFBF = ls[2]\n",
    "BACKUP_OBJECTS = ls[3]\n",
    "\n",
    "# # save new ones before join then reload\n",
    "# SDRO.write.options(header='true').format('com.databricks.spark.csv').save(data_dir + \"/upscale_\" + str(end) + \"_SDRO\")\n",
    "# SS_POOLS.write.options(header='true').format('com.databricks.spark.csv').save(data_dir + \"/upscale_\" + str(end) + \"_SS_POOLS\")\n",
    "# AFBF.write.options(header='true').format('com.databricks.spark.csv').save(data_dir + \"/upscale_\" + str(end) + \"_AFBF\")\n",
    "# BACKUP_OBJECTS.write.options(header='true').format('com.databricks.spark.csv').save(data_dir + \"/upscale_\" + str(end) + \"_BACKUP_OBJECTS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDRO = None\n",
    "# SS_POOLS = None\n",
    "# AFBF = None\n",
    "# BACKUP_OBJECTS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDRO = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load(data_dir + \"/upscale_\" + str(end) + \"_SDRO/*.csv\")\n",
    "# SS_POOLS = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load(data_dir + \"/upscale_\" + str(end) + \"_SS_POOLS/*.csv\")\n",
    "# AFBF = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load(data_dir + \"/upscale_\" + str(end) + \"_AFBF/*.csv\")\n",
    "# BACKUP_OBJECTS = sqlContext.read.format('com.databricks.spark.csv').option(\"header\", \"true\").load(data_dir + \"/upscale_\" + str(end) + \"_BACKUP_OBJECTS/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_outer_join = BACKUP_OBJECTS.join(AFBF, BACKUP_OBJECTS.OBJID == AFBF.BFID,how='left') # Could also use 'full_outer'\n",
    "full_outer_join = full_outer_join.join(SDRO, ['OBJID'],how='left') # Could also use 'full_outer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDRO = None\n",
    "SS_POOLS = None\n",
    "AFBF = None\n",
    "BACKUP_OBJECTS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_outer_join\n",
    "df = df.filter(df.POOLID. isNotNull())\n",
    "df = df.withColumn(\"POOLID\", df[\"POOLID\"].cast(\"int\"))\n",
    "df = df.filter(df.ATTRLENGTH. isNotNull())\n",
    "df = df.withColumn(\"ATTRLENGTH\", df[\"ATTRLENGTH\"].cast(\"float\"))\n",
    "df = df.filter(df.BFSIZE. isNotNull())\n",
    "df = df.withColumn(\"BFSIZE\", df[\"BFSIZE\"].cast(\"float\"))\n",
    "df = df.filter(df.HDRSIZE. isNotNull())\n",
    "df = df.withColumn(\"HDRSIZE\", df[\"HDRSIZE\"].cast(\"float\"))\n",
    "df = df.filter(df.OBJID. isNotNull())\n",
    "df = df.withColumn(\"OBJID\", df[\"OBJID\"].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when   \n",
    "\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == -1000000, 0).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == -9, 1).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == 4, 2).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == 6, 3).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == 42, 4).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == 72, 5).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == 82, 6).otherwise(df['POOLID']))\n",
    "df = df.withColumn('POOLID', when(df['POOLID'] == -1, 7).otherwise(df['POOLID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df.POOLID. isNotNull())\n",
    "df = df.withColumn(\"POOLID\", df[\"POOLID\"].cast(\"int\"))\n",
    "df = df.filter(df.ATTRLENGTH. isNotNull())\n",
    "df = df.withColumn(\"ATTRLENGTH\", df[\"ATTRLENGTH\"].cast(\"float\"))\n",
    "df = df.filter(df.BFSIZE. isNotNull())\n",
    "df = df.withColumn(\"BFSIZE\", df[\"BFSIZE\"].cast(\"float\"))\n",
    "df = df.filter(df.HDRSIZE. isNotNull())\n",
    "df = df.withColumn(\"HDRSIZE\", df[\"HDRSIZE\"].cast(\"float\"))\n",
    "df = df.filter(df.OBJID. isNotNull())\n",
    "df = df.withColumn(\"OBJID\", df[\"OBJID\"].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o327.save.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:196)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 28.0 failed 1 times, most recent failure: Lost task 3.0 in stage 28.0 (TID 2070, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:254)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:168)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: java.lang.NoSuchMethodError: sun.nio.ch.DirectBuffer.cleaner()Lsun/misc/Cleaner;\n\tat org.apache.spark.storage.StorageUtils$.cleanDirectBuffer(StorageUtils.scala:212)\n\tat org.apache.spark.storage.StorageUtils$.dispose(StorageUtils.scala:207)\n\tat org.apache.spark.storage.StorageUtils.dispose(StorageUtils.scala)\n\tat org.apache.spark.io.NioBufferedFileInputStream.close(NioBufferedFileInputStream.java:130)\n\tat java.base/java.io.FilterInputStream.close(FilterInputStream.java:180)\n\tat org.apache.spark.io.ReadAheadInputStream.close(ReadAheadInputStream.java:400)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.close(UnsafeSorterSpillReader.java:152)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.loadNext(UnsafeSorterSpillReader.java:124)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger$1.loadNext(UnsafeSorterSpillMerger.java:82)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:187)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:174)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage45.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:773)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:917)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:953)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage46.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:241)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:239)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:245)\n\t... 10 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:166)\n\t... 32 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:254)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:168)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n\t... 1 more\nCaused by: java.lang.NoSuchMethodError: sun.nio.ch.DirectBuffer.cleaner()Lsun/misc/Cleaner;\n\tat org.apache.spark.storage.StorageUtils$.cleanDirectBuffer(StorageUtils.scala:212)\n\tat org.apache.spark.storage.StorageUtils$.dispose(StorageUtils.scala:207)\n\tat org.apache.spark.storage.StorageUtils.dispose(StorageUtils.scala)\n\tat org.apache.spark.io.NioBufferedFileInputStream.close(NioBufferedFileInputStream.java:130)\n\tat java.base/java.io.FilterInputStream.close(FilterInputStream.java:180)\n\tat org.apache.spark.io.ReadAheadInputStream.close(ReadAheadInputStream.java:400)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.close(UnsafeSorterSpillReader.java:152)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.loadNext(UnsafeSorterSpillReader.java:124)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger$1.loadNext(UnsafeSorterSpillMerger.java:82)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:187)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:174)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage45.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:773)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:917)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:953)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage46.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:241)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:239)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:245)\n\t... 10 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f520f7431134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OBJID\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ATTRLENGTH\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BFSIZE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HDRSIZE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"POOLID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'com.databricks.spark.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/merge_data/upscale\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o327.save.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:196)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:564)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 28.0 failed 1 times, most recent failure: Lost task 3.0 in stage 28.0 (TID 2070, localhost, executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:254)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:168)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n\tat java.base/java.lang.Thread.run(Thread.java:844)\nCaused by: java.lang.NoSuchMethodError: sun.nio.ch.DirectBuffer.cleaner()Lsun/misc/Cleaner;\n\tat org.apache.spark.storage.StorageUtils$.cleanDirectBuffer(StorageUtils.scala:212)\n\tat org.apache.spark.storage.StorageUtils$.dispose(StorageUtils.scala:207)\n\tat org.apache.spark.storage.StorageUtils.dispose(StorageUtils.scala)\n\tat org.apache.spark.io.NioBufferedFileInputStream.close(NioBufferedFileInputStream.java:130)\n\tat java.base/java.io.FilterInputStream.close(FilterInputStream.java:180)\n\tat org.apache.spark.io.ReadAheadInputStream.close(ReadAheadInputStream.java:400)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.close(UnsafeSorterSpillReader.java:152)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.loadNext(UnsafeSorterSpillReader.java:124)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger$1.loadNext(UnsafeSorterSpillMerger.java:82)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:187)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:174)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage45.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:773)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:917)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:953)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage46.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:241)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:239)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:245)\n\t... 10 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:166)\n\t... 32 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:254)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:169)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:168)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)\n\t... 1 more\nCaused by: java.lang.NoSuchMethodError: sun.nio.ch.DirectBuffer.cleaner()Lsun/misc/Cleaner;\n\tat org.apache.spark.storage.StorageUtils$.cleanDirectBuffer(StorageUtils.scala:212)\n\tat org.apache.spark.storage.StorageUtils$.dispose(StorageUtils.scala:207)\n\tat org.apache.spark.storage.StorageUtils.dispose(StorageUtils.scala)\n\tat org.apache.spark.io.NioBufferedFileInputStream.close(NioBufferedFileInputStream.java:130)\n\tat java.base/java.io.FilterInputStream.close(FilterInputStream.java:180)\n\tat org.apache.spark.io.ReadAheadInputStream.close(ReadAheadInputStream.java:400)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.close(UnsafeSorterSpillReader.java:152)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillReader.loadNext(UnsafeSorterSpillReader.java:124)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeSorterSpillMerger$1.loadNext(UnsafeSorterSpillMerger.java:82)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:187)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter$1.next(UnsafeExternalRowSorter.java:174)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage45.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.RowIteratorFromScala.advanceNext(RowIterator.scala:83)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.advancedBufferedToRowWithNullFreeJoinKey(SortMergeJoinExec.scala:811)\n\tat org.apache.spark.sql.execution.joins.SortMergeJoinScanner.findNextOuterJoinRows(SortMergeJoinExec.scala:773)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceStream(SortMergeJoinExec.scala:917)\n\tat org.apache.spark.sql.execution.joins.OneSideOuterIterator.advanceNext(SortMergeJoinExec.scala:953)\n\tat org.apache.spark.sql.execution.RowIteratorToScala.hasNext(RowIterator.scala:68)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage46.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:241)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:239)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:245)\n\t... 10 more\n"
     ]
    }
   ],
   "source": [
    "df.select(\"OBJID\", \"ATTRLENGTH\", \"BFSIZE\", \"HDRSIZE\", \"POOLID\").write.options(header='true').format('com.databricks.spark.csv').save(data_dir + \"/merge_data/upscale\")\n",
    "                                                                                                    \n",
    "                                                                                                                                                   \n",
    "                                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import glob, os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocess\n",
    "def data_preprocess(next):\n",
    "\n",
    "    tf_features = [next['OBJID'], next['ATTRLENGTH'], next['BFSIZE'], next['HDRSIZE']]\n",
    "    features_columns = np.array(sess.run(tf_features), dtype='float32')\n",
    "\n",
    "    #Normalization\n",
    "    for column in range(4):\n",
    "        column_range = features_columns[column].max() - features_columns[column].min()\n",
    "        if column_range != 0.0: \n",
    "            features_columns[column] = (features_columns[column] - features_columns[column].min())/column_range\n",
    "    # print(features_columns)\n",
    "\n",
    "    features = np.array([]).reshape(0,4)\n",
    "    for i in range(batch_len):\n",
    "        ele = np.zeros(4)\n",
    "        np.put(ele,0,features_columns[0][i])\n",
    "        np.put(ele,1,features_columns[1][i])\n",
    "        np.put(ele,2,features_columns[2][i])\n",
    "        np.put(ele,3,features_columns[3][i])\n",
    "        features = np.r_[features, [ele]]\n",
    "    # print(features)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tf_labels = next['POOLID']\n",
    "    labels = np.array(sess.run(tf_labels), dtype='float32')\n",
    "#     print(labels)\n",
    "\n",
    "    # One-hot encoding for the categories\n",
    "    num_classes = 8\n",
    "    targets = np.array([]).reshape(0,num_classes)\n",
    "\n",
    "    for i in range(0,batch_len):\n",
    "        ele = np.zeros(num_classes)\n",
    "        np.put(ele,labels[i],1)\n",
    "        targets = np.r_[targets, [ele]]\n",
    "    \n",
    "#     return features, targets\n",
    "    \n",
    "#     Shuffle Data\n",
    "    indices = np.random.choice(len(features), len(features), replace=False)\n",
    "    X_data = features[indices]\n",
    "    y_data = targets[indices]\n",
    "    \n",
    "    X_values = features[indices]\n",
    "    y_values = targets[indices]\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train, y_train, start_epoch):\n",
    "    \n",
    "    # Interval / Epochs\n",
    "    interval = 500\n",
    "    epoch = 1000\n",
    "\n",
    "    # Training the model...\n",
    "    for i in range(1, (epoch + 1)):\n",
    "        sess.run(optimizer, feed_dict={X_data: X_train, y_target: y_train})\n",
    "        if i % interval == 0:\n",
    "            print('Epoch', i + start_epoch, '|', 'Loss:', sess.run(loss, feed_dict={X_data: X_train, y_target: y_train}))\n",
    "            \n",
    "    return i + start_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the accuracy of the model\n",
    "def predict(X_test, y_test):\n",
    "    correct_prediction = tf.equal(tf.argmax(final_output, 1), tf.argmax(y_target,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"The accuracy of the model is:\", sess.run(accuracy, feed_dict={X_data: X_test, y_target: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A neural Network which contains 3 layers with 4, 10, 8 nodes repectively was created!\n"
     ]
    }
   ],
   "source": [
    "# define a neural network\n",
    "\n",
    "# Initialize placeholders\n",
    "X_data = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 8], dtype=tf.float32)\n",
    "\n",
    "#create seed for random_normal()\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "output_nodes = 8\n",
    "\n",
    "hidden_layer_nodes = 10\n",
    "# We create a neural Network which contains 3 layers with 4, 10, 5 nodes repectively\n",
    "w1 = tf.Variable(tf.random_normal(shape=[4,hidden_layer_nodes])) # Weight of the input layer\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))   # Bias of the input layer\n",
    "w2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,output_nodes])) # Weight of the hidden layer\n",
    "b2 = tf.Variable(tf.random_normal(shape=[output_nodes]))                    # Bias of the hidden layer\n",
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(X_data, w1), b1))\n",
    "final_output = tf.nn.softmax(tf.add(tf.matmul(hidden_output, w2), b2))\n",
    "\n",
    "# Loss Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_target * tf.log(final_output), axis=0))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "print(\"A neural Network which contains 3 layers with 4, 10, 8 nodes repectively was created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 500 | Loss: 490.78394\n",
      "Epoch 1000 | Loss: 489.7601\n",
      "Epoch 1500 | Loss: 419.50906\n",
      "Epoch 2000 | Loss: 419.46417\n",
      "Epoch 2500 | Loss: 398.63068\n",
      "Epoch 3000 | Loss: 398.46466\n",
      "Epoch 3500 | Loss: 427.59354\n",
      "Epoch 4000 | Loss: 427.49258\n",
      "Epoch 4500 | Loss: 501.05963\n",
      "Epoch 5000 | Loss: 500.88696\n",
      "Epoch 5500 | Loss: 500.2516\n",
      "Epoch 6000 | Loss: 500.09613\n",
      "Epoch 6500 | Loss: 401.18964\n",
      "Epoch 7000 | Loss: 401.10922\n",
      "Epoch 7500 | Loss: 482.98828\n",
      "Epoch 8000 | Loss: 482.8815\n",
      "Epoch 8500 | Loss: 445.6189\n",
      "Epoch 9000 | Loss: 445.52692\n",
      "Epoch 9500 | Loss: 474.564\n",
      "Epoch 10000 | Loss: 474.43018\n",
      "Epoch 10500 | Loss: 357.07388\n",
      "Epoch 11000 | Loss: 356.95068\n",
      "Epoch 11500 | Loss: 473.06824\n",
      "Epoch 12000 | Loss: 473.0255\n",
      "Epoch 12500 | Loss: 448.16013\n",
      "Epoch 13000 | Loss: 448.05545\n",
      "Epoch 13500 | Loss: 460.31232\n",
      "Epoch 14000 | Loss: 460.02808\n",
      "Epoch 14500 | Loss: 480.48035\n",
      "Epoch 15000 | Loss: 480.25665\n",
      "Epoch 15500 | Loss: 453.58847\n",
      "Epoch 16000 | Loss: 453.5126\n",
      "Epoch 16500 | Loss: 567.5461\n",
      "Epoch 17000 | Loss: 567.494\n",
      "Epoch 17500 | Loss: 415.7639\n",
      "Epoch 18000 | Loss: 415.43713\n",
      "Epoch 18500 | Loss: 415.16418\n",
      "Epoch 19000 | Loss: 415.0403\n",
      "Epoch 19500 | Loss: 479.24115\n",
      "Epoch 20000 | Loss: 479.1801\n",
      "Epoch 20500 | Loss: 492.44708\n",
      "Epoch 21000 | Loss: 492.234\n",
      "Epoch 21500 | Loss: 442.89893\n",
      "Epoch 22000 | Loss: 442.79825\n",
      "Epoch 22500 | Loss: 550.2051\n",
      "Epoch 23000 | Loss: 550.1134\n",
      "Epoch 23500 | Loss: 644.7361\n",
      "Epoch 24000 | Loss: 644.45483\n",
      "Epoch 24500 | Loss: 511.78174\n",
      "Epoch 25000 | Loss: 511.64557\n",
      "Epoch 25500 | Loss: 508.44897\n",
      "Epoch 26000 | Loss: 508.341\n",
      "Epoch 26500 | Loss: 508.82806\n",
      "Epoch 27000 | Loss: 508.7143\n",
      "Epoch 27500 | Loss: 517.7308\n",
      "Epoch 28000 | Loss: 517.5829\n",
      "Epoch 28500 | Loss: 529.2639\n",
      "Epoch 29000 | Loss: 529.07275\n",
      "Epoch 29500 | Loss: 426.5749\n",
      "Epoch 30000 | Loss: 426.34598\n",
      "Epoch 30500 | Loss: 506.3441\n",
      "Epoch 31000 | Loss: 506.0323\n",
      "Epoch 31500 | Loss: 573.295\n",
      "Epoch 32000 | Loss: 573.1798\n",
      "Epoch 32500 | Loss: 410.62045\n",
      "Epoch 33000 | Loss: 410.45703\n",
      "Epoch 33500 | Loss: 439.58554\n",
      "Epoch 34000 | Loss: 439.4755\n",
      "Epoch 34500 | Loss: 389.46674\n",
      "Epoch 35000 | Loss: 389.36285\n",
      "Epoch 35500 | Loss: 436.7159\n",
      "Epoch 36000 | Loss: 436.55362\n",
      "Epoch 36500 | Loss: 456.24554\n",
      "Epoch 37000 | Loss: 456.09686\n",
      "Epoch 37500 | Loss: 377.18808\n",
      "Epoch 38000 | Loss: 377.07312\n",
      "Epoch 38500 | Loss: 400.4741\n",
      "Epoch 39000 | Loss: 400.38718\n",
      "Epoch 39500 | Loss: 497.4187\n",
      "Epoch 40000 | Loss: 497.3747\n",
      "Epoch 40500 | Loss: 518.04315\n",
      "Epoch 41000 | Loss: 517.97284\n",
      "Epoch 41500 | Loss: 426.84656\n",
      "Epoch 42000 | Loss: 426.70404\n",
      "Epoch 42500 | Loss: 418.8902\n",
      "Epoch 43000 | Loss: 418.63257\n",
      "Epoch 43500 | Loss: 407.59747\n",
      "Epoch 44000 | Loss: 407.53162\n",
      "Epoch 44500 | Loss: 604.44495\n",
      "Epoch 45000 | Loss: 604.31464\n",
      "Epoch 45500 | Loss: 501.53003\n",
      "Epoch 46000 | Loss: 501.37915\n",
      "Epoch 46500 | Loss: 392.57776\n",
      "Epoch 47000 | Loss: 392.3455\n",
      "Epoch 47500 | Loss: 401.80206\n",
      "Epoch 48000 | Loss: 401.7016\n",
      "Epoch 48500 | Loss: 488.6541\n",
      "Epoch 49000 | Loss: 488.50037\n",
      "Epoch 49500 | Loss: 428.01645\n",
      "Epoch 50000 | Loss: 427.84988\n",
      "Epoch 50500 | Loss: 499.2566\n",
      "Epoch 51000 | Loss: 499.18393\n",
      "Epoch 51500 | Loss: 483.90173\n",
      "Epoch 52000 | Loss: 483.81265\n",
      "Epoch 52500 | Loss: 447.29565\n",
      "Epoch 53000 | Loss: 447.2489\n",
      "Epoch 53500 | Loss: 502.02008\n",
      "Epoch 54000 | Loss: 501.84384\n",
      "Epoch 54500 | Loss: 557.85565\n",
      "Epoch 55000 | Loss: 557.74615\n",
      "Epoch 55500 | Loss: 591.2476\n",
      "Epoch 56000 | Loss: 591.1562\n",
      "Epoch 56500 | Loss: 430.3606\n",
      "Epoch 57000 | Loss: 430.3164\n",
      "Epoch 57500 | Loss: 519.76733\n",
      "Epoch 58000 | Loss: 519.6839\n",
      "Epoch 58500 | Loss: 618.0879\n",
      "Epoch 59000 | Loss: 617.9586\n",
      "Epoch 59500 | Loss: 574.51556\n",
      "Epoch 60000 | Loss: 574.2066\n",
      "Epoch 60500 | Loss: 455.29443\n",
      "Epoch 61000 | Loss: 455.15057\n",
      "Epoch 61500 | Loss: 527.5623\n",
      "Epoch 62000 | Loss: 527.5089\n",
      "Epoch 62500 | Loss: 482.90222\n",
      "Epoch 63000 | Loss: 482.85303\n",
      "Epoch 63500 | Loss: 481.71045\n",
      "Epoch 64000 | Loss: 481.56085\n",
      "Epoch 64500 | Loss: 490.8731\n",
      "Epoch 65000 | Loss: 490.3822\n",
      "Epoch 65500 | Loss: 397.96045\n",
      "Epoch 66000 | Loss: 397.7424\n",
      "Epoch 66500 | Loss: 370.1073\n",
      "Epoch 67000 | Loss: 370.06403\n",
      "Epoch 67500 | Loss: 414.01337\n",
      "Epoch 68000 | Loss: 413.9037\n",
      "Epoch 68500 | Loss: 567.8834\n",
      "Epoch 69000 | Loss: 567.69666\n",
      "Epoch 69500 | Loss: 419.26184\n",
      "Epoch 70000 | Loss: 419.06912\n",
      "Epoch 70500 | Loss: 529.12787\n",
      "Epoch 71000 | Loss: 528.9516\n",
      "Epoch 71500 | Loss: 453.79333\n",
      "Epoch 72000 | Loss: 453.60968\n",
      "Epoch 72500 | Loss: 552.39044\n",
      "Epoch 73000 | Loss: 552.2434\n",
      "Epoch 73500 | Loss: 483.55963\n",
      "Epoch 74000 | Loss: 483.41772\n",
      "Epoch 74500 | Loss: 438.28464\n",
      "Epoch 75000 | Loss: 438.19675\n",
      "Epoch 75500 | Loss: 513.5005\n",
      "Epoch 76000 | Loss: 513.39453\n",
      "Epoch 76500 | Loss: 509.00836\n",
      "Epoch 77000 | Loss: 508.95343\n",
      "Epoch 77500 | Loss: 483.8958\n",
      "Epoch 78000 | Loss: 483.6891\n",
      "Epoch 78500 | Loss: 439.57733\n",
      "Epoch 79000 | Loss: 439.43488\n",
      "Epoch 79500 | Loss: 569.55273\n",
      "Epoch 80000 | Loss: 569.35284\n",
      "Epoch 80500 | Loss: 448.20676\n",
      "Epoch 81000 | Loss: 448.08942\n",
      "Epoch 81500 | Loss: 424.81015\n",
      "Epoch 82000 | Loss: 424.71515\n",
      "Epoch 82500 | Loss: 488.34863\n",
      "Epoch 83000 | Loss: 488.22202\n",
      "Epoch 83500 | Loss: 493.179\n",
      "Epoch 84000 | Loss: 493.13455\n",
      "Epoch 84500 | Loss: 481.6611\n",
      "Epoch 85000 | Loss: 481.56445\n",
      "Epoch 85500 | Loss: 398.54105\n",
      "Epoch 86000 | Loss: 398.3391\n",
      "Epoch 86500 | Loss: 410.43225\n",
      "Epoch 87000 | Loss: 410.2924\n",
      "Epoch 87500 | Loss: 524.1927\n",
      "Epoch 88000 | Loss: 524.1019\n",
      "Epoch 88500 | Loss: 382.77618\n",
      "Epoch 89000 | Loss: 382.651\n",
      "Epoch 89500 | Loss: 476.2969\n",
      "Epoch 90000 | Loss: 476.14838\n",
      "Epoch 90500 | Loss: 543.90906\n",
      "Epoch 91000 | Loss: 543.8303\n",
      "Epoch 91500 | Loss: 503.96637\n",
      "Epoch 92000 | Loss: 503.9322\n",
      "Epoch 92500 | Loss: 400.61108\n",
      "Epoch 93000 | Loss: 400.59604\n",
      "Epoch 93500 | Loss: 450.77313\n",
      "Epoch 94000 | Loss: 450.7211\n",
      "Epoch 94500 | Loss: 455.6484\n",
      "Epoch 95000 | Loss: 455.49225\n",
      "Epoch 95500 | Loss: 387.75247\n",
      "Epoch 96000 | Loss: 387.67877\n",
      "Epoch 96500 | Loss: 409.1552\n",
      "Epoch 97000 | Loss: 408.9161\n",
      "Epoch 97500 | Loss: 429.4748\n",
      "Epoch 98000 | Loss: 429.29755\n",
      "Epoch 98500 | Loss: 429.88654\n",
      "Epoch 99000 | Loss: 429.75345\n",
      "Epoch 99500 | Loss: 524.4666\n",
      "Epoch 100000 | Loss: 524.3651\n",
      "Epoch 100500 | Loss: 372.60834\n",
      "Epoch 101000 | Loss: 372.54022\n",
      "Epoch 101500 | Loss: 398.8327\n",
      "Epoch 102000 | Loss: 398.78323\n",
      "Epoch 102500 | Loss: 507.05917\n",
      "Epoch 103000 | Loss: 506.9959\n",
      "Epoch 103500 | Loss: 551.06335\n",
      "Epoch 104000 | Loss: 550.95715\n",
      "Epoch 104500 | Loss: 396.36166\n",
      "Epoch 105000 | Loss: 396.2494\n",
      "Epoch 105500 | Loss: 458.80908\n",
      "Epoch 106000 | Loss: 458.6411\n",
      "Epoch 106500 | Loss: 454.83667\n",
      "Epoch 107000 | Loss: 454.66687\n",
      "Epoch 107500 | Loss: 575.9989\n",
      "Epoch 108000 | Loss: 575.718\n",
      "Epoch 108500 | Loss: 445.83542\n",
      "Epoch 109000 | Loss: 445.68854\n",
      "Epoch 109500 | Loss: 525.11945\n",
      "Epoch 110000 | Loss: 525.0081\n",
      "Epoch 110500 | Loss: 473.98782\n",
      "Epoch 111000 | Loss: 473.89212\n",
      "Epoch 111500 | Loss: 391.61288\n",
      "Epoch 112000 | Loss: 391.47922\n",
      "Epoch 112500 | Loss: 445.10413\n",
      "Epoch 113000 | Loss: 444.93167\n",
      "Epoch 113500 | Loss: 474.4201\n",
      "Epoch 114000 | Loss: 474.2569\n",
      "Epoch 114500 | Loss: 447.44543\n",
      "Epoch 115000 | Loss: 447.34335\n",
      "Epoch 115500 | Loss: 471.96936\n",
      "Epoch 116000 | Loss: 471.87213\n",
      "Epoch 116500 | Loss: 489.52158\n",
      "Epoch 117000 | Loss: 489.4228\n",
      "Epoch 117500 | Loss: 464.4176\n",
      "Epoch 118000 | Loss: 464.3441\n",
      "Epoch 118500 | Loss: 436.44516\n",
      "Epoch 119000 | Loss: 436.31567\n",
      "Epoch 119500 | Loss: 474.27814\n",
      "Epoch 120000 | Loss: 474.23096\n",
      "Epoch 120500 | Loss: 506.09085\n",
      "Epoch 121000 | Loss: 505.99738\n",
      "Epoch 121500 | Loss: 431.245\n",
      "Epoch 122000 | Loss: 431.12766\n",
      "Epoch 122500 | Loss: 352.51025\n",
      "Epoch 123000 | Loss: 352.3973\n",
      "Epoch 123500 | Loss: 488.68033\n",
      "Epoch 124000 | Loss: 488.5597\n",
      "Epoch 124500 | Loss: 522.1472\n",
      "Epoch 125000 | Loss: 522.08826\n",
      "Epoch 125500 | Loss: 495.89133\n",
      "Epoch 126000 | Loss: 495.79053\n",
      "Epoch 126500 | Loss: 427.46713\n",
      "Epoch 127000 | Loss: 427.21936\n",
      "Epoch 127500 | Loss: 556.67535\n",
      "Epoch 128000 | Loss: 556.5718\n",
      "Epoch 128500 | Loss: 558.2101\n",
      "Epoch 129000 | Loss: 558.05994\n",
      "Epoch 129500 | Loss: 435.74512\n",
      "Epoch 130000 | Loss: 435.67722\n",
      "Epoch 130500 | Loss: 493.49597\n",
      "Epoch 131000 | Loss: 493.42404\n",
      "Epoch 131500 | Loss: 480.13403\n",
      "Epoch 132000 | Loss: 479.9433\n",
      "Epoch 132500 | Loss: 390.4249\n",
      "Epoch 133000 | Loss: 390.3649\n",
      "Epoch 133500 | Loss: 405.7229\n",
      "Epoch 134000 | Loss: 405.62006\n",
      "Epoch 134500 | Loss: 476.73785\n",
      "Epoch 135000 | Loss: 476.69376\n",
      "Epoch 135500 | Loss: 490.9301\n",
      "Epoch 136000 | Loss: 490.58112\n",
      "Epoch 136500 | Loss: 484.80914\n",
      "Epoch 137000 | Loss: 484.62476\n",
      "Epoch 137500 | Loss: 523.70966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138000 | Loss: 523.5697\n",
      "Epoch 138500 | Loss: 520.1055\n",
      "Epoch 139000 | Loss: 519.88525\n",
      "Epoch 139500 | Loss: 514.4246\n",
      "Epoch 140000 | Loss: 514.3289\n",
      "Epoch 140500 | Loss: 426.8908\n",
      "Epoch 141000 | Loss: 426.86285\n",
      "Epoch 141500 | Loss: 428.77466\n",
      "Epoch 142000 | Loss: 428.66644\n",
      "Epoch 142500 | Loss: 576.944\n",
      "Epoch 143000 | Loss: 576.787\n",
      "Epoch 143500 | Loss: 476.45667\n",
      "Epoch 144000 | Loss: 476.30945\n",
      "Epoch 144500 | Loss: 385.0522\n",
      "Epoch 145000 | Loss: 384.86017\n",
      "Epoch 145500 | Loss: 415.39075\n",
      "Epoch 146000 | Loss: 415.3487\n",
      "Epoch 146500 | Loss: 529.153\n",
      "Epoch 147000 | Loss: 528.89996\n",
      "Epoch 147500 | Loss: 568.35406\n",
      "Epoch 148000 | Loss: 568.1748\n",
      "Epoch 148500 | Loss: 525.522\n",
      "Epoch 149000 | Loss: 525.4246\n",
      "Epoch 149500 | Loss: 476.36368\n",
      "Epoch 150000 | Loss: 476.2697\n",
      "Epoch 150500 | Loss: 441.2401\n",
      "Epoch 151000 | Loss: 441.12662\n",
      "Epoch 151500 | Loss: 491.79437\n",
      "Epoch 152000 | Loss: 491.70087\n",
      "Epoch 152500 | Loss: 454.1596\n",
      "Epoch 153000 | Loss: 454.02472\n",
      "Epoch 153500 | Loss: 489.31006\n",
      "Epoch 154000 | Loss: 489.1809\n",
      "Epoch 154500 | Loss: 500.5451\n",
      "Epoch 155000 | Loss: 500.29993\n",
      "Epoch 155500 | Loss: 411.9523\n",
      "Epoch 156000 | Loss: 411.9242\n",
      "Epoch 156500 | Loss: 517.87823\n",
      "Epoch 157000 | Loss: 517.7025\n",
      "Epoch 157500 | Loss: 564.3595\n",
      "Epoch 158000 | Loss: 564.2927\n",
      "Epoch 158500 | Loss: 393.1809\n",
      "Epoch 159000 | Loss: 393.059\n",
      "Epoch 159500 | Loss: 437.0058\n",
      "Epoch 160000 | Loss: 436.92264\n",
      "Epoch 160500 | Loss: 389.53976\n",
      "Epoch 161000 | Loss: 389.3994\n",
      "Epoch 161500 | Loss: 416.30292\n",
      "Epoch 162000 | Loss: 416.2543\n",
      "Epoch 162500 | Loss: 515.17334\n",
      "Epoch 163000 | Loss: 515.067\n",
      "Epoch 163500 | Loss: 417.098\n",
      "Epoch 164000 | Loss: 416.9443\n",
      "Epoch 164500 | Loss: 468.26532\n",
      "Epoch 165000 | Loss: 468.16968\n",
      "Epoch 165500 | Loss: 545.6984\n",
      "Epoch 166000 | Loss: 545.64105\n",
      "Epoch 166500 | Loss: 432.29498\n",
      "Epoch 167000 | Loss: 432.23657\n",
      "Epoch 167500 | Loss: 474.65906\n",
      "Epoch 168000 | Loss: 474.39267\n",
      "Epoch 168500 | Loss: 518.764\n",
      "Epoch 169000 | Loss: 518.6343\n",
      "Epoch 169500 | Loss: 427.1755\n",
      "Epoch 170000 | Loss: 427.05273\n",
      "Epoch 170500 | Loss: 342.225\n",
      "Epoch 171000 | Loss: 342.19254\n",
      "Epoch 171500 | Loss: 397.16833\n",
      "Epoch 172000 | Loss: 397.14032\n",
      "Epoch 172500 | Loss: 431.8615\n",
      "Epoch 173000 | Loss: 431.85016\n",
      "Epoch 173500 | Loss: 455.88593\n",
      "Epoch 174000 | Loss: 455.75702\n",
      "Epoch 174500 | Loss: 487.07187\n",
      "Epoch 175000 | Loss: 487.03372\n",
      "Epoch 175500 | Loss: 412.33548\n",
      "Epoch 176000 | Loss: 412.02753\n",
      "Epoch 176500 | Loss: 533.75946\n",
      "Epoch 177000 | Loss: 533.63983\n",
      "Epoch 177500 | Loss: 547.4529\n",
      "Epoch 178000 | Loss: 547.3707\n",
      "Epoch 178500 | Loss: 421.50433\n",
      "Epoch 179000 | Loss: 421.47406\n",
      "Epoch 179500 | Loss: 389.96707\n",
      "Epoch 180000 | Loss: 389.8935\n",
      "Epoch 180500 | Loss: 421.3727\n",
      "Epoch 181000 | Loss: 421.3217\n",
      "Epoch 181500 | Loss: 474.67172\n",
      "Epoch 182000 | Loss: 474.64935\n",
      "Epoch 182500 | Loss: 376.9073\n",
      "Epoch 183000 | Loss: 376.8205\n",
      "Epoch 183500 | Loss: 422.523\n",
      "Epoch 184000 | Loss: 422.3772\n",
      "Epoch 184500 | Loss: 415.45746\n",
      "Epoch 185000 | Loss: 415.4147\n",
      "Epoch 185500 | Loss: 503.9583\n",
      "Epoch 186000 | Loss: 503.8507\n",
      "Epoch 186500 | Loss: 501.43805\n",
      "Epoch 187000 | Loss: 501.32886\n",
      "Epoch 187500 | Loss: 454.38052\n",
      "Epoch 188000 | Loss: 454.23428\n",
      "Epoch 188500 | Loss: 551.9441\n",
      "Epoch 189000 | Loss: 551.82245\n",
      "Epoch 189500 | Loss: 610.06793\n",
      "Epoch 190000 | Loss: 609.55676\n",
      "Epoch 190500 | Loss: 514.3265\n",
      "Epoch 191000 | Loss: 514.2083\n",
      "Epoch 191500 | Loss: 440.01163\n",
      "Epoch 192000 | Loss: 439.948\n",
      "Epoch 192500 | Loss: 484.08322\n",
      "Epoch 193000 | Loss: 484.01978\n",
      "Epoch 193500 | Loss: 502.40823\n",
      "Epoch 194000 | Loss: 502.39407\n",
      "Epoch 194500 | Loss: 445.31815\n",
      "Epoch 195000 | Loss: 445.27402\n",
      "Epoch 195500 | Loss: 526.7301\n",
      "Epoch 196000 | Loss: 526.6213\n",
      "Epoch 196500 | Loss: 430.38837\n",
      "Epoch 197000 | Loss: 430.15253\n",
      "Epoch 197500 | Loss: 360.05167\n",
      "Epoch 198000 | Loss: 359.99713\n",
      "Epoch 198500 | Loss: 472.9297\n",
      "Epoch 199000 | Loss: 472.82422\n",
      "Epoch 199500 | Loss: 449.10568\n",
      "Epoch 200000 | Loss: 449.06598\n",
      "Epoch 200500 | Loss: 440.13922\n",
      "Epoch 201000 | Loss: 440.0949\n",
      "Epoch 201500 | Loss: 502.74792\n",
      "Epoch 202000 | Loss: 502.6958\n",
      "Epoch 202500 | Loss: 522.67834\n",
      "Epoch 203000 | Loss: 522.604\n",
      "Epoch 203500 | Loss: 468.74094\n",
      "Epoch 204000 | Loss: 468.712\n",
      "Epoch 204500 | Loss: 497.3969\n",
      "Epoch 205000 | Loss: 497.23834\n",
      "Epoch 205500 | Loss: 540.0542\n",
      "Epoch 206000 | Loss: 539.975\n",
      "Epoch 206500 | Loss: 488.05322\n",
      "Epoch 207000 | Loss: 488.00787\n",
      "Epoch 207500 | Loss: 358.2171\n",
      "Epoch 208000 | Loss: 358.1841\n",
      "Epoch 208500 | Loss: 478.37018\n",
      "Epoch 209000 | Loss: 478.25012\n",
      "Epoch 209500 | Loss: 468.6336\n",
      "Epoch 210000 | Loss: 468.53442\n",
      "Epoch 210500 | Loss: 337.11224\n",
      "Epoch 211000 | Loss: 337.02338\n",
      "Epoch 211500 | Loss: 517.95795\n",
      "Epoch 212000 | Loss: 517.86005\n",
      "Epoch 212500 | Loss: 504.9282\n",
      "Epoch 213000 | Loss: 504.62735\n",
      "Epoch 213500 | Loss: 375.4624\n",
      "Epoch 214000 | Loss: 375.32864\n",
      "Epoch 214500 | Loss: 323.7936\n",
      "Epoch 215000 | Loss: 323.72397\n",
      "Epoch 215500 | Loss: 425.92343\n",
      "Epoch 216000 | Loss: 425.8591\n",
      "Epoch 216500 | Loss: 494.3448\n",
      "Epoch 217000 | Loss: 494.15338\n",
      "Epoch 217500 | Loss: 485.8805\n",
      "Epoch 218000 | Loss: 485.68\n",
      "Epoch 218500 | Loss: 465.13095\n",
      "Epoch 219000 | Loss: 464.982\n",
      "Epoch 219500 | Loss: 466.6769\n",
      "Epoch 220000 | Loss: 466.555\n",
      "Epoch 220500 | Loss: 471.02893\n",
      "Epoch 221000 | Loss: 471.00323\n",
      "Epoch 221500 | Loss: 445.70255\n",
      "Epoch 222000 | Loss: 445.59338\n",
      "Epoch 222500 | Loss: 387.96927\n",
      "Epoch 223000 | Loss: 387.909\n",
      "Epoch 223500 | Loss: 508.50903\n",
      "Epoch 224000 | Loss: 508.44495\n",
      "Epoch 224500 | Loss: 417.7575\n",
      "Epoch 225000 | Loss: 417.62262\n",
      "Epoch 225500 | Loss: 531.3938\n",
      "Epoch 226000 | Loss: 531.3352\n",
      "Epoch 226500 | Loss: 553.66956\n",
      "Epoch 227000 | Loss: 553.6519\n",
      "Epoch 227500 | Loss: 495.17694\n",
      "Epoch 228000 | Loss: 494.9517\n",
      "Epoch 228500 | Loss: 419.20923\n",
      "Epoch 229000 | Loss: 419.1557\n",
      "Epoch 229500 | Loss: 415.70978\n",
      "Epoch 230000 | Loss: 415.6311\n",
      "Epoch 230500 | Loss: 539.87555\n",
      "Epoch 231000 | Loss: 539.7842\n",
      "Epoch 231500 | Loss: 549.50037\n",
      "Epoch 232000 | Loss: 549.3638\n",
      "Epoch 232500 | Loss: 474.29297\n",
      "Epoch 233000 | Loss: 473.98108\n",
      "Epoch 233500 | Loss: 416.20154\n",
      "Epoch 234000 | Loss: 416.15738\n",
      "Epoch 234500 | Loss: 453.7949\n",
      "Epoch 235000 | Loss: 453.74225\n",
      "Epoch 235500 | Loss: 517.1184\n",
      "Epoch 236000 | Loss: 516.991\n",
      "Epoch 236500 | Loss: 518.34814\n",
      "Epoch 237000 | Loss: 518.29456\n",
      "Epoch 237500 | Loss: 473.47107\n",
      "Epoch 238000 | Loss: 473.40552\n",
      "Epoch 238500 | Loss: 476.1489\n",
      "Epoch 239000 | Loss: 475.97308\n",
      "Epoch 239500 | Loss: 468.76\n",
      "Epoch 240000 | Loss: 468.72363\n",
      "Epoch 240500 | Loss: 511.56094\n",
      "Epoch 241000 | Loss: 511.44388\n",
      "Epoch 241500 | Loss: 438.9787\n",
      "Epoch 242000 | Loss: 438.91458\n",
      "Epoch 242500 | Loss: 538.3468\n",
      "Epoch 243000 | Loss: 538.23895\n",
      "Epoch 243500 | Loss: 501.65952\n",
      "Epoch 244000 | Loss: 501.50638\n",
      "Epoch 244500 | Loss: 379.33838\n",
      "Epoch 245000 | Loss: 379.28543\n",
      "Epoch 245500 | Loss: 447.70868\n",
      "Epoch 246000 | Loss: 447.66455\n",
      "Epoch 246500 | Loss: 531.4155\n",
      "Epoch 247000 | Loss: 531.32947\n",
      "Epoch 247500 | Loss: 480.4372\n",
      "Epoch 248000 | Loss: 480.29996\n",
      "Epoch 248500 | Loss: 414.99118\n",
      "Epoch 249000 | Loss: 414.87946\n",
      "Epoch 249500 | Loss: 387.01376\n",
      "Epoch 250000 | Loss: 386.89575\n",
      "Epoch 250500 | Loss: 460.24286\n",
      "Epoch 251000 | Loss: 460.08798\n",
      "Epoch 251500 | Loss: 411.91412\n",
      "Epoch 252000 | Loss: 411.8742\n",
      "Epoch 252500 | Loss: 347.3151\n",
      "Epoch 253000 | Loss: 347.1965\n",
      "Epoch 253500 | Loss: 443.04398\n",
      "Epoch 254000 | Loss: 442.9331\n",
      "Epoch 254500 | Loss: 463.56543\n",
      "Epoch 255000 | Loss: 463.44125\n",
      "Epoch 255500 | Loss: 458.30414\n",
      "Epoch 256000 | Loss: 458.2453\n",
      "Epoch 256500 | Loss: 571.1638\n",
      "Epoch 257000 | Loss: 571.04224\n",
      "Epoch 257500 | Loss: 533.04297\n",
      "Epoch 258000 | Loss: 532.9503\n",
      "Epoch 258500 | Loss: 462.5604\n",
      "Epoch 259000 | Loss: 462.40656\n",
      "Epoch 259500 | Loss: 552.5277\n",
      "Epoch 260000 | Loss: 552.4934\n",
      "Epoch 260500 | Loss: 469.09753\n",
      "Epoch 261000 | Loss: 469.02444\n",
      "Epoch 261500 | Loss: 457.4164\n",
      "Epoch 262000 | Loss: 457.1749\n",
      "Epoch 262500 | Loss: 446.1738\n",
      "Epoch 263000 | Loss: 446.08362\n",
      "Epoch 263500 | Loss: 539.0473\n",
      "Epoch 264000 | Loss: 538.9908\n",
      "Epoch 264500 | Loss: 489.7492\n",
      "Epoch 265000 | Loss: 489.63257\n",
      "Epoch 265500 | Loss: 440.90717\n",
      "Epoch 266000 | Loss: 440.8662\n",
      "Epoch 266500 | Loss: 566.0152\n",
      "Epoch 267000 | Loss: 565.9544\n",
      "Epoch 267500 | Loss: 525.8811\n",
      "Epoch 268000 | Loss: 525.7735\n",
      "Epoch 268500 | Loss: 473.6891\n",
      "Epoch 269000 | Loss: 473.4843\n",
      "Epoch 269500 | Loss: 363.34088\n",
      "Epoch 270000 | Loss: 363.2479\n",
      "Epoch 270500 | Loss: 517.15985\n",
      "Epoch 271000 | Loss: 517.5316\n",
      "Epoch 271500 | Loss: 422.769\n",
      "Epoch 272000 | Loss: 422.70148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 272500 | Loss: 494.39053\n",
      "Epoch 273000 | Loss: 494.1733\n",
      "Epoch 273500 | Loss: 501.2752\n",
      "Epoch 274000 | Loss: 501.148\n",
      "Epoch 274500 | Loss: 419.45865\n",
      "Epoch 275000 | Loss: 419.36212\n",
      "Epoch 275500 | Loss: 389.8629\n",
      "Epoch 276000 | Loss: 389.79312\n",
      "Epoch 276500 | Loss: 394.49728\n",
      "Epoch 277000 | Loss: 394.4687\n",
      "Epoch 277500 | Loss: 386.50854\n",
      "Epoch 278000 | Loss: 386.411\n",
      "Epoch 278500 | Loss: 396.98456\n",
      "Epoch 279000 | Loss: 396.92145\n",
      "Epoch 279500 | Loss: 450.9663\n",
      "Epoch 280000 | Loss: 450.70148\n",
      "Epoch 280500 | Loss: 476.74274\n",
      "Epoch 281000 | Loss: 476.649\n",
      "Epoch 281500 | Loss: 518.4534\n",
      "Epoch 282000 | Loss: 518.39154\n",
      "Epoch 282500 | Loss: 450.47632\n",
      "Epoch 283000 | Loss: 450.39487\n",
      "Epoch 283500 | Loss: 453.24167\n",
      "Epoch 284000 | Loss: 453.12457\n",
      "Epoch 284500 | Loss: 428.34702\n",
      "Epoch 285000 | Loss: 428.30408\n",
      "Epoch 285500 | Loss: 480.5935\n",
      "Epoch 286000 | Loss: 480.55728\n",
      "Epoch 286500 | Loss: 392.58365\n",
      "Epoch 287000 | Loss: 392.5579\n",
      "Epoch 287500 | Loss: 399.16107\n",
      "Epoch 288000 | Loss: 399.07278\n",
      "Epoch 288500 | Loss: 451.4917\n",
      "Epoch 289000 | Loss: 451.41467\n",
      "Epoch 289500 | Loss: 510.44626\n",
      "Epoch 290000 | Loss: 510.3161\n",
      "Epoch 290500 | Loss: 456.34042\n",
      "Epoch 291000 | Loss: 456.29346\n",
      "Epoch 291500 | Loss: 389.6947\n",
      "Epoch 292000 | Loss: 389.58487\n",
      "Epoch 292500 | Loss: 462.8327\n",
      "Epoch 293000 | Loss: 462.49796\n",
      "Epoch 293500 | Loss: 559.5052\n",
      "Epoch 294000 | Loss: 559.1584\n",
      "Epoch 294500 | Loss: 418.096\n",
      "Epoch 295000 | Loss: 418.026\n",
      "Epoch 295500 | Loss: 442.4005\n",
      "Epoch 296000 | Loss: 442.3106\n",
      "Epoch 296500 | Loss: 376.95886\n",
      "Epoch 297000 | Loss: 376.9087\n",
      "Epoch 297500 | Loss: 551.34607\n",
      "Epoch 298000 | Loss: 551.2075\n",
      "Epoch 298500 | Loss: 448.50012\n",
      "Epoch 299000 | Loss: 448.3939\n",
      "Epoch 299500 | Loss: 374.3776\n",
      "Epoch 300000 | Loss: 374.28635\n",
      "Epoch 300500 | Loss: 440.9876\n",
      "Epoch 301000 | Loss: 440.94223\n",
      "Epoch 301500 | Loss: 493.86288\n",
      "Epoch 302000 | Loss: 493.78088\n",
      "Epoch 302500 | Loss: 376.442\n",
      "Epoch 303000 | Loss: 376.3902\n",
      "Epoch 303500 | Loss: 373.41916\n",
      "Epoch 304000 | Loss: 373.24823\n",
      "Epoch 304500 | Loss: 495.5855\n",
      "Epoch 305000 | Loss: 495.44992\n",
      "Epoch 305500 | Loss: 537.24664\n",
      "Epoch 306000 | Loss: 537.167\n",
      "Epoch 306500 | Loss: 447.5304\n",
      "Epoch 307000 | Loss: 447.3807\n",
      "Epoch 307500 | Loss: 389.62552\n",
      "Epoch 308000 | Loss: 389.50928\n",
      "Epoch 308500 | Loss: 453.89474\n",
      "Epoch 309000 | Loss: 453.725\n",
      "Epoch 309500 | Loss: 472.31653\n",
      "Epoch 310000 | Loss: 472.2652\n",
      "Epoch 310500 | Loss: 388.9235\n",
      "Epoch 311000 | Loss: 388.74518\n",
      "Epoch 311500 | Loss: 464.6501\n",
      "Epoch 312000 | Loss: 464.51447\n",
      "Epoch 312500 | Loss: 426.1515\n",
      "Epoch 313000 | Loss: 426.00577\n",
      "Epoch 313500 | Loss: 370.2254\n",
      "Epoch 314000 | Loss: 370.08276\n",
      "Epoch 314500 | Loss: 451.74808\n",
      "Epoch 315000 | Loss: 451.6576\n",
      "Epoch 315500 | Loss: 534.9075\n",
      "Epoch 316000 | Loss: 534.69104\n",
      "Epoch 316500 | Loss: 454.1961\n",
      "Epoch 317000 | Loss: 454.10974\n",
      "Epoch 317500 | Loss: 429.34045\n",
      "Epoch 318000 | Loss: 429.23062\n",
      "Epoch 318500 | Loss: 481.34152\n",
      "Epoch 319000 | Loss: 481.0843\n",
      "Epoch 319500 | Loss: 469.9062\n",
      "Epoch 320000 | Loss: 469.70056\n",
      "Epoch 320500 | Loss: 468.8996\n",
      "Epoch 321000 | Loss: 468.78415\n",
      "Epoch 321500 | Loss: 404.39465\n",
      "Epoch 322000 | Loss: 404.35498\n",
      "Epoch 322500 | Loss: 470.6985\n",
      "Epoch 323000 | Loss: 470.58502\n",
      "Epoch 323500 | Loss: 500.85248\n",
      "Epoch 324000 | Loss: 500.7588\n",
      "Epoch 324500 | Loss: 525.7868\n",
      "Epoch 325000 | Loss: 525.665\n",
      "Epoch 325500 | Loss: 447.06973\n",
      "Epoch 326000 | Loss: 446.99725\n",
      "Epoch 326500 | Loss: 330.0382\n",
      "Epoch 327000 | Loss: 329.99457\n",
      "Epoch 327500 | Loss: 525.5067\n",
      "Epoch 328000 | Loss: 525.33344\n",
      "Epoch 328500 | Loss: 406.4068\n",
      "Epoch 329000 | Loss: 405.94116\n",
      "Epoch 329500 | Loss: 449.0585\n",
      "Epoch 330000 | Loss: 448.71365\n",
      "Epoch 330500 | Loss: 569.9589\n",
      "Epoch 331000 | Loss: 569.78406\n",
      "Epoch 331500 | Loss: 491.30423\n",
      "Epoch 332000 | Loss: 491.1632\n",
      "Epoch 332500 | Loss: 406.71173\n",
      "Epoch 333000 | Loss: 406.521\n",
      "Epoch 333500 | Loss: 601.5996\n",
      "Epoch 334000 | Loss: 601.52563\n",
      "Epoch 334500 | Loss: 490.10995\n",
      "Epoch 335000 | Loss: 490.04355\n",
      "Epoch 335500 | Loss: 421.25458\n",
      "Epoch 336000 | Loss: 421.0501\n",
      "Epoch 336500 | Loss: 549.38794\n",
      "Epoch 337000 | Loss: 549.3329\n",
      "Epoch 337500 | Loss: 557.81836\n",
      "Epoch 338000 | Loss: 557.5782\n",
      "Epoch 338500 | Loss: 446.9664\n",
      "Epoch 339000 | Loss: 446.89893\n",
      "Epoch 339500 | Loss: 469.73157\n",
      "Epoch 340000 | Loss: 469.67523\n",
      "Epoch 340500 | Loss: 499.7563\n",
      "Epoch 341000 | Loss: 499.72638\n",
      "Epoch 341500 | Loss: 519.08875\n",
      "Epoch 342000 | Loss: 518.8816\n",
      "Epoch 342500 | Loss: 406.18774\n",
      "Epoch 343000 | Loss: 406.13474\n",
      "Epoch 343500 | Loss: 465.7312\n",
      "Epoch 344000 | Loss: 465.5995\n",
      "Epoch 344500 | Loss: 509.73383\n",
      "Epoch 345000 | Loss: 509.669\n",
      "Epoch 345500 | Loss: 486.96558\n",
      "Epoch 346000 | Loss: 486.92422\n",
      "Epoch 346500 | Loss: 477.40207\n",
      "Epoch 347000 | Loss: 477.2801\n",
      "Epoch 347500 | Loss: 583.5034\n",
      "Epoch 348000 | Loss: 583.3176\n",
      "Epoch 348500 | Loss: 556.0592\n",
      "Epoch 349000 | Loss: 555.98413\n",
      "Epoch 349500 | Loss: 401.82855\n",
      "Epoch 350000 | Loss: 401.69543\n",
      "Epoch 350500 | Loss: 446.15265\n",
      "Epoch 351000 | Loss: 446.02808\n",
      "Epoch 351500 | Loss: 546.4089\n",
      "Epoch 352000 | Loss: 546.3138\n",
      "Epoch 352500 | Loss: 534.4521\n",
      "Epoch 353000 | Loss: 533.9835\n",
      "Epoch 353500 | Loss: 536.46295\n",
      "Epoch 354000 | Loss: 536.3624\n",
      "Epoch 354500 | Loss: 401.4131\n",
      "Epoch 355000 | Loss: 401.17975\n",
      "Epoch 355500 | Loss: 377.30438\n",
      "Epoch 356000 | Loss: 377.1622\n",
      "Epoch 356500 | Loss: 408.02414\n",
      "Epoch 357000 | Loss: 407.93466\n",
      "Epoch 357500 | Loss: 531.6161\n",
      "Epoch 358000 | Loss: 531.5351\n",
      "Epoch 358500 | Loss: 515.0998\n",
      "Epoch 359000 | Loss: 515.0762\n",
      "Epoch 359500 | Loss: 404.35977\n",
      "Epoch 360000 | Loss: 404.22772\n",
      "Epoch 360500 | Loss: 477.63367\n",
      "Epoch 361000 | Loss: 477.5642\n",
      "Epoch 361500 | Loss: 501.09064\n",
      "Epoch 362000 | Loss: 501.05893\n",
      "Epoch 362500 | Loss: 492.28345\n",
      "Epoch 363000 | Loss: 492.22003\n",
      "Epoch 363500 | Loss: 497.81024\n",
      "Epoch 364000 | Loss: 497.74707\n",
      "Epoch 364500 | Loss: 486.1134\n",
      "Epoch 365000 | Loss: 486.06955\n",
      "Epoch 365500 | Loss: 485.0016\n",
      "Epoch 366000 | Loss: 484.8589\n",
      "Epoch 366500 | Loss: 437.23627\n",
      "Epoch 367000 | Loss: 437.11224\n",
      "Epoch 367500 | Loss: 356.2777\n",
      "Epoch 368000 | Loss: 356.1448\n",
      "Epoch 368500 | Loss: 369.68048\n",
      "Epoch 369000 | Loss: 369.61255\n",
      "Epoch 369500 | Loss: 475.45917\n",
      "Epoch 370000 | Loss: 475.42087\n",
      "Epoch 370500 | Loss: 535.7394\n",
      "Epoch 371000 | Loss: 535.53906\n",
      "Epoch 371500 | Loss: 470.81262\n",
      "Epoch 372000 | Loss: 470.72668\n",
      "Epoch 372500 | Loss: 566.89624\n",
      "Epoch 373000 | Loss: 566.7927\n",
      "Epoch 373500 | Loss: 543.28394\n",
      "Epoch 374000 | Loss: 543.1994\n",
      "Epoch 374500 | Loss: 529.2059\n",
      "Epoch 375000 | Loss: 529.13324\n",
      "Epoch 375500 | Loss: 485.04633\n",
      "Epoch 376000 | Loss: 485.00006\n",
      "Epoch 376500 | Loss: 524.7468\n",
      "Epoch 377000 | Loss: 524.7044\n",
      "Epoch 377500 | Loss: 567.78815\n",
      "Epoch 378000 | Loss: 567.5112\n",
      "Epoch 378500 | Loss: 530.92725\n",
      "Epoch 379000 | Loss: 530.79486\n",
      "Epoch 379500 | Loss: 411.04565\n",
      "Epoch 380000 | Loss: 411.00052\n",
      "Epoch 380500 | Loss: 373.84805\n",
      "Epoch 381000 | Loss: 373.72696\n",
      "Epoch 381500 | Loss: 521.68585\n",
      "Epoch 382000 | Loss: 521.59296\n",
      "Epoch 382500 | Loss: 622.2503\n",
      "Epoch 383000 | Loss: 622.1515\n",
      "Epoch 383500 | Loss: 512.1922\n",
      "Epoch 384000 | Loss: 512.03894\n",
      "Epoch 384500 | Loss: 478.59442\n",
      "Epoch 385000 | Loss: 478.5596\n",
      "Epoch 385500 | Loss: 496.11597\n",
      "Epoch 386000 | Loss: 496.0517\n",
      "Epoch 386500 | Loss: 505.88434\n",
      "Epoch 387000 | Loss: 505.72888\n",
      "Epoch 387500 | Loss: 471.23572\n",
      "Epoch 388000 | Loss: 471.17764\n",
      "Epoch 388500 | Loss: 489.7467\n",
      "Epoch 389000 | Loss: 489.6588\n",
      "Epoch 389500 | Loss: 403.75974\n",
      "Epoch 390000 | Loss: 403.52426\n",
      "Epoch 390500 | Loss: 414.32285\n",
      "Epoch 391000 | Loss: 414.20813\n",
      "Epoch 391500 | Loss: 481.50055\n",
      "Epoch 392000 | Loss: 481.34827\n",
      "Epoch 392500 | Loss: 540.295\n",
      "Epoch 393000 | Loss: 540.2192\n",
      "Epoch 393500 | Loss: 442.06543\n",
      "Epoch 394000 | Loss: 442.01437\n",
      "Epoch 394500 | Loss: 416.0916\n",
      "Epoch 395000 | Loss: 416.02197\n",
      "Epoch 395500 | Loss: 534.6056\n",
      "Epoch 396000 | Loss: 534.5627\n",
      "Epoch 396500 | Loss: 415.93658\n",
      "Epoch 397000 | Loss: 415.76672\n",
      "Epoch 397500 | Loss: 441.13455\n",
      "Epoch 398000 | Loss: 441.0307\n",
      "Epoch 398500 | Loss: 496.72733\n",
      "Epoch 399000 | Loss: 496.61935\n",
      "Epoch 399500 | Loss: 362.70508\n",
      "Epoch 400000 | Loss: 362.60153\n",
      "Epoch 400500 | Loss: 515.29987\n",
      "Epoch 401000 | Loss: 515.1785\n",
      "Epoch 401500 | Loss: 497.62463\n",
      "Epoch 402000 | Loss: 497.5827\n",
      "Epoch 402500 | Loss: 441.34778\n",
      "Epoch 403000 | Loss: 441.25122\n",
      "Epoch 403500 | Loss: 443.94867\n",
      "Epoch 404000 | Loss: 443.67603\n",
      "Epoch 404500 | Loss: 504.72766\n",
      "Epoch 405000 | Loss: 504.60242\n",
      "Epoch 405500 | Loss: 487.71558\n",
      "Epoch 406000 | Loss: 487.60608\n",
      "Epoch 406500 | Loss: 442.5708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407000 | Loss: 442.50748\n",
      "Epoch 407500 | Loss: 443.93893\n",
      "Epoch 408000 | Loss: 443.82843\n",
      "Epoch 408500 | Loss: 486.38565\n",
      "Epoch 409000 | Loss: 486.3337\n",
      "Epoch 409500 | Loss: 544.1964\n",
      "Epoch 410000 | Loss: 544.1368\n",
      "Epoch 410500 | Loss: 414.0881\n",
      "Epoch 411000 | Loss: 414.05222\n",
      "Epoch 411500 | Loss: 535.72675\n",
      "Epoch 412000 | Loss: 535.6966\n",
      "Epoch 412500 | Loss: 545.82263\n",
      "Epoch 413000 | Loss: 545.7491\n",
      "Epoch 413500 | Loss: 360.4565\n",
      "Epoch 414000 | Loss: 360.37302\n",
      "Epoch 414500 | Loss: 534.4185\n",
      "Epoch 415000 | Loss: 533.96466\n",
      "Epoch 415500 | Loss: 527.1288\n",
      "Epoch 416000 | Loss: 527.06085\n",
      "Epoch 416500 | Loss: 422.91214\n",
      "Epoch 417000 | Loss: 422.73346\n",
      "Epoch 417500 | Loss: 522.9353\n",
      "Epoch 418000 | Loss: 522.8579\n",
      "Epoch 418500 | Loss: 472.06888\n",
      "Epoch 419000 | Loss: 471.94012\n",
      "Epoch 419500 | Loss: 434.78467\n",
      "Epoch 420000 | Loss: 434.63123\n",
      "Epoch 420500 | Loss: 438.56506\n",
      "Epoch 421000 | Loss: 438.42105\n",
      "Epoch 421500 | Loss: 475.69073\n",
      "Epoch 422000 | Loss: 475.5691\n",
      "Epoch 422500 | Loss: 380.48282\n",
      "Epoch 423000 | Loss: 380.31018\n",
      "Epoch 423500 | Loss: 403.32904\n",
      "Epoch 424000 | Loss: 403.27142\n",
      "Epoch 424500 | Loss: 434.78052\n",
      "Epoch 425000 | Loss: 434.73334\n",
      "Epoch 425500 | Loss: 488.59232\n",
      "Epoch 426000 | Loss: 488.52963\n",
      "Epoch 426500 | Loss: 535.50134\n",
      "Epoch 427000 | Loss: 535.2822\n",
      "Epoch 427500 | Loss: 556.78613\n",
      "Epoch 428000 | Loss: 556.67786\n",
      "Epoch 428500 | Loss: 495.52124\n",
      "Epoch 429000 | Loss: 495.4307\n",
      "Epoch 429500 | Loss: 534.2275\n",
      "Epoch 430000 | Loss: 534.15845\n",
      "Epoch 430500 | Loss: 521.0728\n",
      "Epoch 431000 | Loss: 520.9979\n",
      "Epoch 431500 | Loss: 411.1945\n",
      "Epoch 432000 | Loss: 411.13766\n",
      "Epoch 432500 | Loss: 449.4478\n",
      "Epoch 433000 | Loss: 449.10583\n",
      "Epoch 433500 | Loss: 466.1933\n",
      "Epoch 434000 | Loss: 466.1138\n",
      "Epoch 434500 | Loss: 423.41043\n",
      "Epoch 435000 | Loss: 423.3534\n",
      "Epoch 435500 | Loss: 413.3967\n",
      "Epoch 436000 | Loss: 413.3608\n",
      "Epoch 436500 | Loss: 390.82028\n",
      "Epoch 437000 | Loss: 390.3668\n",
      "Epoch 437500 | Loss: 427.15573\n",
      "Epoch 438000 | Loss: 426.99548\n",
      "Epoch 438500 | Loss: 555.3571\n",
      "Epoch 439000 | Loss: 555.26556\n",
      "Epoch 439500 | Loss: 442.6509\n",
      "Epoch 440000 | Loss: 442.5409\n",
      "Epoch 440500 | Loss: 493.46997\n",
      "Epoch 441000 | Loss: 493.37195\n",
      "Epoch 441500 | Loss: 566.07367\n",
      "Epoch 442000 | Loss: 566.0215\n",
      "Epoch 442500 | Loss: 510.22495\n",
      "Epoch 443000 | Loss: 509.94562\n",
      "Epoch 443500 | Loss: 472.9627\n",
      "Epoch 444000 | Loss: 472.93024\n",
      "Epoch 444500 | Loss: 418.49756\n",
      "Epoch 445000 | Loss: 418.41992\n",
      "Epoch 445500 | Loss: 460.42706\n",
      "Epoch 446000 | Loss: 460.37164\n",
      "Epoch 446500 | Loss: 464.70322\n",
      "Epoch 447000 | Loss: 464.66467\n",
      "Epoch 447500 | Loss: 425.91104\n",
      "Epoch 448000 | Loss: 425.8731\n",
      "Epoch 448500 | Loss: 472.42346\n",
      "Epoch 449000 | Loss: 472.30832\n",
      "Epoch 449500 | Loss: 528.8916\n",
      "Epoch 450000 | Loss: 528.81067\n",
      "Epoch 450500 | Loss: 396.30243\n",
      "Epoch 451000 | Loss: 396.28006\n",
      "Epoch 451500 | Loss: 441.98068\n",
      "Epoch 452000 | Loss: 441.93414\n",
      "Epoch 452500 | Loss: 515.39734\n",
      "Epoch 453000 | Loss: 515.34875\n",
      "Epoch 453500 | Loss: 392.30862\n",
      "Epoch 454000 | Loss: 392.2264\n",
      "Epoch 454500 | Loss: 423.90375\n",
      "Epoch 455000 | Loss: 423.83676\n",
      "Epoch 455500 | Loss: 511.22208\n",
      "Epoch 456000 | Loss: 511.13245\n",
      "Epoch 456500 | Loss: 558.55505\n",
      "Epoch 457000 | Loss: 558.49744\n",
      "Epoch 457500 | Loss: 553.15564\n",
      "Epoch 458000 | Loss: 553.1162\n",
      "Epoch 458500 | Loss: 453.86182\n",
      "Epoch 459000 | Loss: 453.8366\n",
      "Epoch 459500 | Loss: 462.98026\n",
      "Epoch 460000 | Loss: 462.9762\n",
      "Epoch 460500 | Loss: 545.292\n",
      "Epoch 461000 | Loss: 545.25366\n",
      "Epoch 461500 | Loss: 457.0495\n",
      "Epoch 462000 | Loss: 457.3019\n",
      "Epoch 462500 | Loss: 402.0458\n",
      "Epoch 463000 | Loss: 401.93005\n",
      "Epoch 463500 | Loss: 459.508\n",
      "Epoch 464000 | Loss: 459.44904\n",
      "Epoch 464500 | Loss: 547.51337\n",
      "Epoch 465000 | Loss: 547.4358\n",
      "Epoch 465500 | Loss: 523.2848\n",
      "Epoch 466000 | Loss: 523.0359\n",
      "Epoch 466500 | Loss: 453.37915\n",
      "Epoch 467000 | Loss: 453.28958\n",
      "Epoch 467500 | Loss: 362.30212\n",
      "Epoch 468000 | Loss: 362.25836\n",
      "Epoch 468500 | Loss: 372.08905\n",
      "Epoch 469000 | Loss: 371.95972\n",
      "Epoch 469500 | Loss: 477.75525\n",
      "Epoch 470000 | Loss: 477.63165\n",
      "Epoch 470500 | Loss: 428.6763\n",
      "Epoch 471000 | Loss: 428.47913\n",
      "Epoch 471500 | Loss: 440.03564\n",
      "Epoch 472000 | Loss: 439.84192\n",
      "Epoch 472500 | Loss: 545.94916\n",
      "Epoch 473000 | Loss: 545.8111\n",
      "Epoch 473500 | Loss: 517.2441\n",
      "Epoch 474000 | Loss: 517.0546\n",
      "Epoch 474500 | Loss: 508.09216\n",
      "Epoch 475000 | Loss: 507.9389\n",
      "Epoch 475500 | Loss: 592.7117\n",
      "Epoch 476000 | Loss: 592.68835\n",
      "Epoch 476500 | Loss: 481.62585\n",
      "Epoch 477000 | Loss: 481.596\n",
      "Epoch 477500 | Loss: 458.5423\n",
      "Epoch 478000 | Loss: 458.52164\n",
      "Epoch 478500 | Loss: 576.88776\n",
      "Epoch 479000 | Loss: 576.7111\n",
      "Epoch 479500 | Loss: 417.81934\n",
      "Epoch 480000 | Loss: 417.6767\n",
      "Epoch 480500 | Loss: 531.55884\n",
      "Epoch 481000 | Loss: 531.37915\n",
      "Epoch 481500 | Loss: 526.44885\n",
      "Epoch 482000 | Loss: 526.3103\n",
      "Epoch 482500 | Loss: 439.60736\n",
      "Epoch 483000 | Loss: 439.55505\n",
      "Epoch 483500 | Loss: 415.78488\n",
      "Epoch 484000 | Loss: 415.76526\n",
      "Epoch 484500 | Loss: 480.51572\n",
      "Epoch 485000 | Loss: 480.398\n",
      "Epoch 485500 | Loss: 543.58295\n",
      "Epoch 486000 | Loss: 543.5447\n",
      "Epoch 486500 | Loss: 473.01718\n",
      "Epoch 487000 | Loss: 472.97125\n",
      "Epoch 487500 | Loss: 533.44495\n",
      "Epoch 488000 | Loss: 533.38635\n",
      "Epoch 488500 | Loss: 548.2873\n",
      "Epoch 489000 | Loss: 548.22516\n",
      "Epoch 489500 | Loss: 487.14264\n",
      "Epoch 490000 | Loss: 487.08786\n",
      "Epoch 490500 | Loss: 392.14462\n",
      "Epoch 491000 | Loss: 392.13214\n",
      "Epoch 491500 | Loss: 505.68604\n",
      "Epoch 492000 | Loss: 505.633\n",
      "Epoch 492500 | Loss: 504.02997\n",
      "Epoch 493000 | Loss: 503.74957\n",
      "Epoch 493500 | Loss: 520.9639\n",
      "Epoch 494000 | Loss: 520.9032\n",
      "Epoch 494500 | Loss: 433.99817\n",
      "Epoch 495000 | Loss: 433.96222\n",
      "Epoch 495500 | Loss: 393.5188\n",
      "Epoch 496000 | Loss: 393.46722\n",
      "Epoch 496500 | Loss: 377.34048\n",
      "Epoch 497000 | Loss: 377.2733\n",
      "Epoch 497500 | Loss: 488.5622\n",
      "Epoch 498000 | Loss: 488.5001\n",
      "Epoch 498500 | Loss: 505.17603\n",
      "Epoch 499000 | Loss: 505.00232\n",
      "Epoch 499500 | Loss: 479.59576\n",
      "Epoch 500000 | Loss: 479.51843\n",
      "Epoch 500500 | Loss: 437.0388\n",
      "Epoch 501000 | Loss: 436.91022\n",
      "Epoch 501500 | Loss: 451.69574\n",
      "Epoch 502000 | Loss: 451.67236\n",
      "Epoch 502500 | Loss: 454.13794\n",
      "Epoch 503000 | Loss: 454.07703\n",
      "Epoch 503500 | Loss: 497.51654\n",
      "Epoch 504000 | Loss: 497.4204\n",
      "Epoch 504500 | Loss: 522.0577\n",
      "Epoch 505000 | Loss: 521.68713\n",
      "Epoch 505500 | Loss: 397.44135\n",
      "Epoch 506000 | Loss: 397.27148\n",
      "Epoch 506500 | Loss: 394.00793\n",
      "Epoch 507000 | Loss: 393.88336\n",
      "Epoch 507500 | Loss: 455.7854\n",
      "Epoch 508000 | Loss: 455.73053\n",
      "Epoch 508500 | Loss: 571.3198\n",
      "Epoch 509000 | Loss: 571.1695\n",
      "Epoch 509500 | Loss: 503.902\n",
      "Epoch 510000 | Loss: 503.77618\n",
      "Epoch 510500 | Loss: 431.0092\n",
      "Epoch 511000 | Loss: 430.95416\n",
      "Epoch 511500 | Loss: 526.9601\n",
      "Epoch 512000 | Loss: 526.6532\n",
      "Epoch 512500 | Loss: 346.53833\n",
      "Epoch 513000 | Loss: 346.44806\n",
      "Epoch 513500 | Loss: 540.21564\n",
      "Epoch 514000 | Loss: 540.14923\n",
      "Epoch 514500 | Loss: 627.76715\n",
      "Epoch 515000 | Loss: 627.3862\n",
      "Epoch 515500 | Loss: 453.05905\n",
      "Epoch 516000 | Loss: 452.99936\n",
      "Epoch 516500 | Loss: 533.1612\n",
      "Epoch 517000 | Loss: 533.0129\n",
      "Epoch 517500 | Loss: 441.1249\n",
      "Epoch 518000 | Loss: 440.98633\n",
      "Epoch 518500 | Loss: 383.94684\n",
      "Epoch 519000 | Loss: 383.8408\n",
      "Epoch 519500 | Loss: 389.4278\n",
      "Epoch 520000 | Loss: 389.31958\n",
      "Epoch 520500 | Loss: 369.0668\n",
      "Epoch 521000 | Loss: 369.03906\n",
      "Epoch 521500 | Loss: 447.48413\n",
      "Epoch 522000 | Loss: 447.46277\n",
      "Epoch 522500 | Loss: 390.6443\n",
      "Epoch 523000 | Loss: 390.55908\n",
      "Epoch 523500 | Loss: 363.1422\n",
      "Epoch 524000 | Loss: 363.12225\n",
      "Epoch 524500 | Loss: 437.74832\n",
      "Epoch 525000 | Loss: 437.60257\n",
      "Epoch 525500 | Loss: 561.82776\n",
      "Epoch 526000 | Loss: 561.2754\n",
      "Epoch 526500 | Loss: 422.00888\n",
      "Epoch 527000 | Loss: 421.9524\n",
      "Epoch 527500 | Loss: 495.6584\n",
      "Epoch 528000 | Loss: 495.5341\n",
      "Epoch 528500 | Loss: 475.78522\n",
      "Epoch 529000 | Loss: 475.74353\n",
      "Epoch 529500 | Loss: 459.89386\n",
      "Epoch 530000 | Loss: 459.83813\n",
      "Epoch 530500 | Loss: 491.8725\n",
      "Epoch 531000 | Loss: 491.76288\n",
      "Epoch 531500 | Loss: 505.16806\n",
      "Epoch 532000 | Loss: 505.0705\n",
      "Epoch 532500 | Loss: 510.3499\n",
      "Epoch 533000 | Loss: 510.30756\n",
      "Epoch 533500 | Loss: 442.8696\n",
      "Epoch 534000 | Loss: 442.7894\n",
      "Epoch 534500 | Loss: 553.7704\n",
      "Epoch 535000 | Loss: 553.7283\n",
      "Epoch 535500 | Loss: 420.01288\n",
      "Epoch 536000 | Loss: 419.9925\n",
      "Epoch 536500 | Loss: 444.26227\n",
      "Epoch 537000 | Loss: 444.24042\n",
      "Epoch 537500 | Loss: 443.63806\n",
      "Epoch 538000 | Loss: 443.60538\n",
      "The accuracy of the model is: 0.64925\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/zhaoluyang/Downloads/Senior-Capstone-2018-2019-master/Notebooks/TestData/merge_data/upscale'                     \n",
    "# path = data_dir + \"/merge_data/upscale\"\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_dataset   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "# print(len(concatenated_dataset))\n",
    "\n",
    "batch_len = 4000\n",
    "dataset = tf.data.experimental.make_csv_dataset(all_files, batch_size=batch_len)\n",
    "# print(dataset)\n",
    "\n",
    "start_epoch = 0\n",
    "print('Training the model...')\n",
    "iter = dataset.make_one_shot_iterator()\n",
    "\n",
    "# Initialize variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "#There are total 2,157,764 rows in the combined csv files\n",
    "\n",
    "#choose first 4000 rows as test data\n",
    "next = iter.get_next()\n",
    "X_test, y_test = data_preprocess(next)\n",
    "\n",
    "#then 538*4000 = 2,152,000 rows will be used as training data\n",
    "for i in range(538):\n",
    "    next = iter.get_next()\n",
    "    # next is a dict with key=columns names and value=column data\n",
    "    X_train, y_train = data_preprocess(next)\n",
    "#     print(X_train)\n",
    "    start_epoch = training(X_train, y_train, start_epoch)\n",
    "    \n",
    "predict(X_test, y_test)\n",
    "    \n",
    "print(\"Training finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model to predict pool id for features:  [[0.6934 0.     0.0029 0.1481]]\n",
      "\n",
      "Predicted softmax vector is:  [[1.5382e-01 4.6839e-02 7.8487e-02 3.1280e-03 7.1770e-01 1.0177e-06\n",
      "  2.5428e-05 8.2960e-08]]\n",
      "\n",
      "Predicted pool id is:  POOLID_-1\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "np.set_printoptions(precision=4)\n",
    "unknown = np.array([[0.693363, 0.0, 0.002894, 0.148097]], dtype=np.float32)\n",
    "predicted = sess.run(final_output, feed_dict={X_data: unknown})\n",
    "# model.predict(unknown)\n",
    "print(\"Using model to predict pool id for features: \", unknown)\n",
    "print(\"\\nPredicted softmax vector is: \",predicted)\n",
    "Class_dict={'POOLID_-1000000': 0, 'POOLID_-9': 1, 'POOLID_-1': 2, 'POOLID_4': 3, 'POOLID_-1': 4, 'POOLID_6': 5, 'POOLID_42': 6, 'POOLID_72': 7, 'POOLID_82': 8 }\n",
    "pool_dict = {v:k for k,v in Class_dict.items()}\n",
    "print(\"\\nPredicted pool id is: \", pool_dict[np.argmax(predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
