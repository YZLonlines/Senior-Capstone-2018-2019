{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training a neural network on Iris dataset using TensorFlow \n",
      "Loading the Iris data to memory...\n",
      "Finish loading\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining a neural network on Iris dataset using TensorFlow \")\n",
    "print(\"Loading the Iris data to memory...\")\n",
    "# Loading the dataset\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "print(\"Finish loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLength  SepalWidth  PetalLength  PetalWidth  Name_Iris-setosa  \\\n",
      "0            5.1         3.5          1.4         0.2                 1   \n",
      "1            4.9         3.0          1.4         0.2                 1   \n",
      "2            4.7         3.2          1.3         0.2                 1   \n",
      "3            4.6         3.1          1.5         0.2                 1   \n",
      "4            5.0         3.6          1.4         0.2                 1   \n",
      "5            5.4         3.9          1.7         0.4                 1   \n",
      "6            4.6         3.4          1.4         0.3                 1   \n",
      "7            5.0         3.4          1.5         0.2                 1   \n",
      "8            4.4         2.9          1.4         0.2                 1   \n",
      "9            4.9         3.1          1.5         0.1                 1   \n",
      "10           5.4         3.7          1.5         0.2                 1   \n",
      "11           4.8         3.4          1.6         0.2                 1   \n",
      "12           4.8         3.0          1.4         0.1                 1   \n",
      "13           4.3         3.0          1.1         0.1                 1   \n",
      "14           5.8         4.0          1.2         0.2                 1   \n",
      "15           5.7         4.4          1.5         0.4                 1   \n",
      "16           5.4         3.9          1.3         0.4                 1   \n",
      "17           5.1         3.5          1.4         0.3                 1   \n",
      "18           5.7         3.8          1.7         0.3                 1   \n",
      "19           5.1         3.8          1.5         0.3                 1   \n",
      "20           5.4         3.4          1.7         0.2                 1   \n",
      "21           5.1         3.7          1.5         0.4                 1   \n",
      "22           4.6         3.6          1.0         0.2                 1   \n",
      "23           5.1         3.3          1.7         0.5                 1   \n",
      "24           4.8         3.4          1.9         0.2                 1   \n",
      "25           5.0         3.0          1.6         0.2                 1   \n",
      "26           5.0         3.4          1.6         0.4                 1   \n",
      "27           5.2         3.5          1.5         0.2                 1   \n",
      "28           5.2         3.4          1.4         0.2                 1   \n",
      "29           4.7         3.2          1.6         0.2                 1   \n",
      "..           ...         ...          ...         ...               ...   \n",
      "120          6.9         3.2          5.7         2.3                 0   \n",
      "121          5.6         2.8          4.9         2.0                 0   \n",
      "122          7.7         2.8          6.7         2.0                 0   \n",
      "123          6.3         2.7          4.9         1.8                 0   \n",
      "124          6.7         3.3          5.7         2.1                 0   \n",
      "125          7.2         3.2          6.0         1.8                 0   \n",
      "126          6.2         2.8          4.8         1.8                 0   \n",
      "127          6.1         3.0          4.9         1.8                 0   \n",
      "128          6.4         2.8          5.6         2.1                 0   \n",
      "129          7.2         3.0          5.8         1.6                 0   \n",
      "130          7.4         2.8          6.1         1.9                 0   \n",
      "131          7.9         3.8          6.4         2.0                 0   \n",
      "132          6.4         2.8          5.6         2.2                 0   \n",
      "133          6.3         2.8          5.1         1.5                 0   \n",
      "134          6.1         2.6          5.6         1.4                 0   \n",
      "135          7.7         3.0          6.1         2.3                 0   \n",
      "136          6.3         3.4          5.6         2.4                 0   \n",
      "137          6.4         3.1          5.5         1.8                 0   \n",
      "138          6.0         3.0          4.8         1.8                 0   \n",
      "139          6.9         3.1          5.4         2.1                 0   \n",
      "140          6.7         3.1          5.6         2.4                 0   \n",
      "141          6.9         3.1          5.1         2.3                 0   \n",
      "142          5.8         2.7          5.1         1.9                 0   \n",
      "143          6.8         3.2          5.9         2.3                 0   \n",
      "144          6.7         3.3          5.7         2.5                 0   \n",
      "145          6.7         3.0          5.2         2.3                 0   \n",
      "146          6.3         2.5          5.0         1.9                 0   \n",
      "147          6.5         3.0          5.2         2.0                 0   \n",
      "148          6.2         3.4          5.4         2.3                 0   \n",
      "149          5.9         3.0          5.1         1.8                 0   \n",
      "\n",
      "     Name_Iris-versicolor  Name_Iris-virginica  \n",
      "0                       0                    0  \n",
      "1                       0                    0  \n",
      "2                       0                    0  \n",
      "3                       0                    0  \n",
      "4                       0                    0  \n",
      "5                       0                    0  \n",
      "6                       0                    0  \n",
      "7                       0                    0  \n",
      "8                       0                    0  \n",
      "9                       0                    0  \n",
      "10                      0                    0  \n",
      "11                      0                    0  \n",
      "12                      0                    0  \n",
      "13                      0                    0  \n",
      "14                      0                    0  \n",
      "15                      0                    0  \n",
      "16                      0                    0  \n",
      "17                      0                    0  \n",
      "18                      0                    0  \n",
      "19                      0                    0  \n",
      "20                      0                    0  \n",
      "21                      0                    0  \n",
      "22                      0                    0  \n",
      "23                      0                    0  \n",
      "24                      0                    0  \n",
      "25                      0                    0  \n",
      "26                      0                    0  \n",
      "27                      0                    0  \n",
      "28                      0                    0  \n",
      "29                      0                    0  \n",
      "..                    ...                  ...  \n",
      "120                     0                    1  \n",
      "121                     0                    1  \n",
      "122                     0                    1  \n",
      "123                     0                    1  \n",
      "124                     0                    1  \n",
      "125                     0                    1  \n",
      "126                     0                    1  \n",
      "127                     0                    1  \n",
      "128                     0                    1  \n",
      "129                     0                    1  \n",
      "130                     0                    1  \n",
      "131                     0                    1  \n",
      "132                     0                    1  \n",
      "133                     0                    1  \n",
      "134                     0                    1  \n",
      "135                     0                    1  \n",
      "136                     0                    1  \n",
      "137                     0                    1  \n",
      "138                     0                    1  \n",
      "139                     0                    1  \n",
      "140                     0                    1  \n",
      "141                     0                    1  \n",
      "142                     0                    1  \n",
      "143                     0                    1  \n",
      "144                     0                    1  \n",
      "145                     0                    1  \n",
      "146                     0                    1  \n",
      "147                     0                    1  \n",
      "148                     0                    1  \n",
      "149                     0                    1  \n",
      "\n",
      "[150 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for the categories\n",
    "dataset = pd.get_dummies(dataset, columns=['Name']) \n",
    "values = list(dataset.columns.values)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.6 5.6 1.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [5.1 3.5 1.4 0.2]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.  3.  4.8 1.8]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [6.  2.2 5.  1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.2 2.8 4.8 1.8]]\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data \n",
    "target = np.array(dataset[values[-3:]], dtype='float32')\n",
    "features = np.array(dataset[values[0:-3]], dtype='float32')\n",
    "\n",
    "# Shuffle Data\n",
    "indices = np.random.choice(len(features), len(features), replace=False)\n",
    "X_values = features[indices]\n",
    "y_values = target[indices]\n",
    "\n",
    "# Creating a Train and a Test Dataset\n",
    "test_size = 30\n",
    "X_test = X_values[-test_size:]\n",
    "X_train = X_values[:-test_size]\n",
    "y_test = y_values[-test_size:]\n",
    "y_train = y_values[:-test_size]\n",
    "\n",
    "print(X_train)\n",
    "# print(X_test)\n",
    "# print(y_test)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A neural Network which contains 3 layers with 4, 8, 3 nodes repectively was created!\n"
     ]
    }
   ],
   "source": [
    "# define a neural network\n",
    "\n",
    "# Initialize placeholders\n",
    "X_data = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 3], dtype=tf.float32)\n",
    "\n",
    "#create seed for random_normal()\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n",
    "\n",
    "hidden_layer_nodes = 8\n",
    "# We create a neural Network which contains 3 layers with 4, 8, 3 nodes repectively\n",
    "w1 = tf.Variable(tf.random_normal(shape=[4,hidden_layer_nodes])) # Weight of the input layer\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))   # Bias of the input layer\n",
    "w2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,3])) # Weight of the hidden layer\n",
    "b2 = tf.Variable(tf.random_normal(shape=[3]))                    # Bias of the hidden layer\n",
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(X_data, w1), b1))\n",
    "final_output = tf.nn.softmax(tf.add(tf.matmul(hidden_output, w2), b2))\n",
    "\n",
    "# Loss Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_target * tf.log(final_output), axis=0))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "print(\"A neural Network which contains 3 layers with 4, 8, 3 nodes repectively was created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 100 | Loss: 15.617526\n",
      "Epoch 200 | Loss: 11.483928\n",
      "Epoch 300 | Loss: 8.14018\n",
      "Epoch 400 | Loss: 6.1576653\n",
      "Epoch 500 | Loss: 5.3353896\n",
      "Epoch 600 | Loss: 4.848772\n",
      "Epoch 700 | Loss: 4.5151687\n",
      "Epoch 800 | Loss: 4.273574\n",
      "Epoch 900 | Loss: 4.0905156\n",
      "Epoch 1000 | Loss: 3.9469602\n",
      "Training finished\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Training the model...')\n",
    "\n",
    "# Interval / Epochs\n",
    "interval = 100\n",
    "epoch = 1000\n",
    "\n",
    "# Initialize variables\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training the model...\n",
    "for i in range(1, (epoch + 1)):\n",
    "    sess.run(optimizer, feed_dict={X_data: X_train, y_target: y_train})\n",
    "    if i % interval == 0:\n",
    "        print('Epoch', i, '|', 'Loss:', sess.run(loss, feed_dict={X_data: X_train, y_target: y_train}))\n",
    "\n",
    "print(\"Training finished\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is: 0.96666664\n"
     ]
    }
   ],
   "source": [
    "# get the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(final_output, 1), tf.argmax(y_target,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"The accuracy of the model is:\", sess.run(accuracy, feed_dict={X_data: X_test, y_target: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model to predict species for features:  [[6.1 3.1 5.1 1.1]]\n",
      "\n",
      "Predicted softmax vector is:  [[3.7255e-04 9.4318e-01 5.6447e-02]]\n",
      "\n",
      "Predicted species is:  Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "np.set_printoptions(precision=4)\n",
    "unknown = np.array([[6.1, 3.1, 5.1, 1.1]], dtype=np.float32)\n",
    "predicted = sess.run(final_output, feed_dict={X_data: unknown})\n",
    "# model.predict(unknown)\n",
    "print(\"Using model to predict species for features: \", unknown)\n",
    "print(\"\\nPredicted softmax vector is: \",predicted)\n",
    "Class_dict={'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "species_dict = {v:k for k,v in Class_dict.items()}\n",
    "print(\"\\nPredicted species is: \", species_dict[np.argmax(predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
